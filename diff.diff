diff --git a/WORKSPACE b/WORKSPACE
index 4bbff9a..868d0b6 100644
--- a/WORKSPACE
+++ b/WORKSPACE
@@ -14,13 +14,15 @@ http_archive(
     patch_args = ["-p1"],
     patches = [
         "//install:openxla.patch",
-        "//install:llvm.patch",
-        "//install/llvm:annc1.patch",
-        "//install/llvm:annc2.patch",
-        "//install/llvm:annc3.patch",
-        "//install/llvm:annc4.patch",
-        "//install/llvm:concat.patch",
-        "//install/xla:mlir_hlo.patch",
+        "//install/xla:BUILD.patch",
+        "//install/xla:cpu_runtime.cc.patch",
+        "//install/xla:cpu_runtime.h.patch",
+        "//install/xla:debug_options_flags.cc.patch",
+        "//install/xla:hlo_xla_runtime_pipeline.h.patch",
+        "//install/xla:ir_emitter.cc.patch",
+        "//install/xla:ir_emitter.h.patch",
+        "//install/xla:simple_orc_jit.cc.patch",
+        "//install/xla:xla.proto.patch",
     ],
     sha256 = "90e72fa3558a69cf2562e4600e62c478d22c3986c642d7dcdc7ef0841ded52c5",
     strip_prefix = "xla-40008cb2c85749ae436be61c40d3279cb24705c7",
diff --git a/annc/service/blas_util.h b/annc/service/blas_util.h
index bb01ae5..9b2adb7 100644
--- a/annc/service/blas_util.h
+++ b/annc/service/blas_util.h
@@ -25,6 +25,14 @@ typedef enum CBLAS_TRANSPOSE {
 
 typedef int blasint;
 
+void cblas_sgemv(OPENBLAS_CONST enum CBLAS_ORDER order,
+                 OPENBLAS_CONST enum CBLAS_TRANSPOSE trans,
+                 OPENBLAS_CONST blasint m, OPENBLAS_CONST blasint n,
+                 OPENBLAS_CONST float alpha, OPENBLAS_CONST float* a,
+                 OPENBLAS_CONST blasint lda, OPENBLAS_CONST float* x,
+                 OPENBLAS_CONST blasint incx, OPENBLAS_CONST float beta,
+                 float* y, OPENBLAS_CONST blasint incy);
+
 void cblas_sgemm(OPENBLAS_CONST enum CBLAS_ORDER Order,
                  OPENBLAS_CONST enum CBLAS_TRANSPOSE TransA,
                  OPENBLAS_CONST enum CBLAS_TRANSPOSE TransB,
@@ -42,4 +50,4 @@ float cblas_sasum(OPENBLAS_CONST blasint n, OPENBLAS_CONST float *x,
 }
 #endif  /* __cplusplus */
 
-#endif  // ANNC_CBLAS_H
\ No newline at end of file
+#endif  // ANNC_CBLAS_H
diff --git a/annc/service/cpu/BUILD b/annc/service/cpu/BUILD
index 867bc68..416bf1d 100644
--- a/annc/service/cpu/BUILD
+++ b/annc/service/cpu/BUILD
@@ -24,31 +24,52 @@ cc_library(
     ],
 )
 
-genrule(
-    name = "generate_empty_hpc",
-    outs = ["dummy.c"],
-    cmd = "touch $@",
-)
-
-cc_binary(
-    name = "hpc.so",
-    srcs = [":dummy.c"],
-    linkshared = True,
-)
-
 cc_library(
     name = "cambridge",
-    srcs = glob(["xla/*.cpp", "xla/*.cc", "llvm/*.cpp", "hpc.so"]),
+    srcs = ["xla/kernel_selector.cc",
+            "xla/kernel_selector_ops_rewriter.cc",
+            "xla/xnnpack_ops.cc",
+            "xla/xnnpack_ops_rewriter.cc",
+            ],
+    hdrs = ["xla/kernel_selector.h",
+            "xla/kernel_selector_ops_rewriter.h",
+            "xla/xnnpack_ops.h",
+            "xla/xnnpack_ops_rewriter.h",
+            "xla/xnnpack_pattern_utils.h",
+            ],
     linkstatic = True,
     alwayslink = True,
     visibility = ["//visibility:public"],
     deps = [
-        "@xla//xla/mlir_hlo:transforms_passes",
-        "@xla//xla/mlir_hlo:thlo_passes",
-        ":hpc.so"
+        "@xla//xla/hlo/ir:hlo",
+        "@xla//xla/service:hlo_pass",
+        "@xla//xla:literal_comparison",
+        "@xla//xla:literal_util",
+        "@xla//xla/service/cpu:cpu_runtime",
+        "@xla//xla/service/cpu:simple_orc_jit",
+        "@xla//xla/service/cpu:runtime_lightweight_check",
+        "@xla//xla:executable_run_options",
+        "@xla//xla/service/cpu:ir_emitter",
+        "@xla//xla/service:pattern_matcher",
+        ":libmlir",
+        ":libXNNPACK",
     ],
 )
 
+cc_import(
+    name = "libXNNPACK",
+    visibility = ["//visibility:public"],
+    shared_library = "xla/libs/libXNNPACK.so",
+    system_provided = 0
+)
+
+cc_import(
+  name = "libmlir",
+  visibility = ["//visibility:public"],
+  shared_library = "xla/libs/libblas_920b_single_mlir.so",
+  system_provided = 0,
+)
+
 cc_binary(
     name = "libannc.so",
     srcs = glob(["*.cc", "*.h"]),
diff --git a/annc/service/cpu/gemm_rewriter.cc b/annc/service/cpu/gemm_rewriter.cc
index c5426c1..81a4468 100644
--- a/annc/service/cpu/gemm_rewriter.cc
+++ b/annc/service/cpu/gemm_rewriter.cc
@@ -97,6 +97,31 @@ void __matmul(void* out, const void** in) {
 #endif
 }
 
+void __matvec(void* out, const void** in) {
+  float* out_buf = reinterpret_cast<float*>(out);
+  const float* lhs = reinterpret_cast<const float*>(in[0]);
+  const float* rhs = reinterpret_cast<const float*>(in[1]);
+  const int64_t* lhs_shape = reinterpret_cast<const int64_t*>(in[2]);
+  const int64_t* rhs_shape = reinterpret_cast<const int64_t*>(in[3]);
+  int m = lhs_shape[0];
+  int n = rhs_shape[1];
+
+#if defined(ANNC_ENABLED_KDNN) || defined(ANNC_ENABLED_OPENBLAS)
+  CBLAS_LAYOUT clayout = CblasRowMajor;
+  CBLAS_TRANSPOSE transa = CblasNoTrans;
+
+  int lda = n;
+  float alpha = 1.0f;
+  float beta = 0.0f;
+  int incx = 1;
+  int incy = 1;
+
+  // Y = alpha * A * X + beta * Y;
+  cblas_sgemv(clayout, transa, m, n, alpha, lhs, lda, rhs, incx, beta,
+                   out_buf, incy);
+#endif
+}
+
 void __batch_matmul(void* out, const void** in) {
   float* out_buf = reinterpret_cast<float*>(out);
   const float* lhs = reinterpret_cast<const float*>(in[0]);
diff --git a/annc/service/cpu/xla/README_kernel_selector.md b/annc/service/cpu/xla/README_kernel_selector.md
new file mode 100644
index 0000000..3a21359
--- /dev/null
+++ b/annc/service/cpu/xla/README_kernel_selector.md
@@ -0,0 +1,52 @@
+<!--
+Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================
+-->
+
+To dynamically map a set of input dimensions to a symbol for the kernel selector:
+
+# For GEMM
+
+Set the `GEMM_MAP_FILE` environment variable to point to a text file. This file must contains lines which look like the following:
+
+```
+(6656,8,8) -> __xla_cpu_runtime_KernelSelectorGEMM
+```
+
+An example file (`gemm_map.txt`) is provided in the current directory.
+
+This means that when m,n,k (in this order) are 6658,8,8 then the selector should use the GEMM implemented by the symbol (6656,8,8) -> __xla_cpu_runtime_KernelSelectorGEMM.
+
+Be mindful of following the exact pattern. This is space-sensitive so will not work if spaces are added inside the tuple, for example.
+
+# For GEMV.
+
+Same as above, but set the `GEMV_MAP_FILE` environment variable. Its content should look like:
+
+```
+(m,n) -> function_name
+```
+
+Where `m`, `n`, are integers for the input sizes.
+
+# For BATCH_MATMUL:
+
+Same as above, but set the `BATCHMATMUL_MAP_FILE` environment variable. Its content should look like:
+
+```
+(p,m,n,k) -> function_name
+```
+
+Where `p`, `m`, `n`, `k` are integers for the input sizes.
\ No newline at end of file
diff --git a/annc/service/cpu/xla/gemm_map.txt b/annc/service/cpu/xla/gemm_map.txt
new file mode 100644
index 0000000..99a88ed
--- /dev/null
+++ b/annc/service/cpu/xla/gemm_map.txt
@@ -0,0 +1 @@
+(6656,8,8) -> __xla_cpu_runtime_KernelSelectorGEMM
diff --git a/annc/service/cpu/xla/kernel_selector.cc b/annc/service/cpu/xla/kernel_selector.cc
new file mode 100644
index 0000000..e07ab9f
--- /dev/null
+++ b/annc/service/cpu/xla/kernel_selector.cc
@@ -0,0 +1,125 @@
+/* Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "kernel_selector.h"
+
+namespace xla {
+namespace cpu {
+
+// TODO: Need to test handling trA, trB
+void __xla_cpu_runtime_KernelSelectorGEMM(bool trA, bool trB, const float* A,
+                                          const float* B, int M, int N, int K,
+                                          float alpha, float beta, float* C) {
+  CBLAS_LAYOUT Order = CblasRowMajor;
+  CBLAS_TRANSPOSE TransA = (trA) ? CblasTrans : CblasNoTrans;
+  CBLAS_TRANSPOSE TransB = (trB) ? CblasTrans : CblasNoTrans;
+  int lda = trA ? M : K;
+  int ldb = trB ? K : N;
+  int ldc = N;
+
+  cblas_sgemm(Order, TransA, TransB, M, N, K, alpha, A, lda, B, ldb, beta, C,
+              ldc);
+}
+
+void __xla_cpu_runtime_KernelSelectorBatch3D(bool trA, bool trB, const float* A,
+                                             const float* B, int P, int M,
+                                             int N, int K, float* C) {
+  CBLAS_LAYOUT Order = CblasRowMajor;
+  CBLAS_TRANSPOSE TransA = (trA) ? CblasTrans : CblasNoTrans;
+  CBLAS_TRANSPOSE TransB = (trB) ? CblasTrans : CblasNoTrans;
+  int lda = trA ? M : K;
+  int ldb = trB ? K : N;
+  int ldc = N;
+
+  float alpha = 1.0;
+  float beta = 0.0;
+
+  for (int i = 0; i < P; ++i) {
+    cblas_sgemm(Order, TransA, TransB, M, N, K, alpha, &A[i * M * K], lda,
+                &B[i * K * N], ldb, beta, &C[i * M * N], ldc);
+  }
+}
+
+void __xla_cpu_runtime_KernelSelectorGEMV(bool trA, const float* A,
+                                          const float* X, int M, int N,
+                                          float alpha, float beta, float* Y) {
+  int lda = trA ? M : N;
+  int incX = 1;
+  int incY = 1;
+  CBLAS_LAYOUT Order = CblasRowMajor;
+  CBLAS_TRANSPOSE TransA = (trA) ? CblasTrans : CblasNoTrans;
+  cblas_sgemv(Order, TransA, M, N, alpha, A, lda, X, incX, beta, Y, incY);
+}
+
+void __xla_cpu_runtime_KernelSelectorGEMMMLIR(bool trA, bool trB,
+                                              const float* A, const float* B,
+                                              int M, int N, int K, float alpha,
+                                              float beta, float* C) {
+  CBLAS_LAYOUT Order = CblasRowMajor;
+  CBLAS_TRANSPOSE TransA = (trA) ? CblasTrans : CblasNoTrans;
+  CBLAS_TRANSPOSE TransB = (trB) ? CblasTrans : CblasNoTrans;
+  int lda = trA ? M : K;
+  int ldb = trB ? K : N;
+  int ldc = N;
+
+  cblas_sgemm_mlir(Order, TransA, TransB, M, N, K, alpha, A, lda, B, ldb, beta,
+                   C, ldc);
+}
+
+void __xla_cpu_runtime_KernelSelectorBatch3DMLIR(bool trA, bool trB,
+                                                 const float* A, const float* B,
+                                                 int P, int M, int N, int K,
+                                                 float* C) {
+  CBLAS_LAYOUT Order = CblasRowMajor;
+  CBLAS_TRANSPOSE TransA = (trA) ? CblasTrans : CblasNoTrans;
+  CBLAS_TRANSPOSE TransB = (trB) ? CblasTrans : CblasNoTrans;
+  int lda = trA ? M : K;
+  int ldb = trB ? K : N;
+  int ldc = N;
+
+  cblas_sbatch_matmul_mlir(Order, TransA, TransB, P, M, N, K, A, lda, B, ldb, C,
+                           ldc);
+}
+
+void __xla_cpu_runtime_KernelSelectorBatch4DMLIR(bool trA, bool trB,
+                                                 const float* A, const float* B,
+                                                 int Q, int P, int M, int N,
+                                                 int K, float* C) {
+  CBLAS_LAYOUT Order = CblasRowMajor;
+  CBLAS_TRANSPOSE TransA = (trA) ? CblasTrans : CblasNoTrans;
+  CBLAS_TRANSPOSE TransB = (trB) ? CblasTrans : CblasNoTrans;
+  int lda = trA ? M : K;
+  int ldb = trB ? K : N;
+  int ldc = N;
+
+  cblas_sbatch_matmul_4d_mlir(Order, TransA, TransB, Q, P, M, N, K, A, lda, B,
+                              ldb, C, ldc);
+}
+
+void __xla_cpu_runtime_KernelSelectorGEMVMLIR(bool trA, const float* A,
+                                              const float* X, int M, int N,
+                                              float alpha, float beta,
+                                              float* Y) {
+  int lda = trA ? M : N;
+  int incX = 1;
+  int incY = 1;
+  CBLAS_LAYOUT Order = CblasRowMajor;
+  CBLAS_TRANSPOSE TransA = (trA) ? CblasTrans : CblasNoTrans;
+
+  cblas_sgemv_mlir(Order, TransA, M, N, alpha, A, lda, X, incX, beta, Y, incY);
+}
+
+}  // namespace cpu
+}  // namespace xla
diff --git a/annc/service/cpu/xla/kernel_selector.h b/annc/service/cpu/xla/kernel_selector.h
new file mode 100644
index 0000000..902dbba
--- /dev/null
+++ b/annc/service/cpu/xla/kernel_selector.h
@@ -0,0 +1,129 @@
+/* Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef XLA_SERVICE_CPU_KERNEL_SELECTOR_H_
+#define XLA_SERVICE_CPU_KERNEL_SELECTOR_H_
+
+namespace xla {
+namespace cpu {
+
+#ifndef OPENBLAS_CONST
+#define OPENBLAS_CONST const
+#endif
+
+typedef enum CBLAS_ORDER {
+  CblasRowMajor = 101,
+  CblasColMajor = 102
+} CBLAS_ORDER;
+
+typedef enum CBLAS_TRANSPOSE {
+  CblasNoTrans = 111,
+  CblasTrans = 112,
+  CblasConjTrans = 113,
+  CblasConjNoTrans = 114
+} CBLAS_TRANSPOSE;
+
+typedef int blasint;
+typedef CBLAS_ORDER CBLAS_LAYOUT;
+
+extern "C" {
+
+// BLAS interface
+extern void cblas_sgemm(OPENBLAS_CONST enum CBLAS_ORDER Order,
+                        OPENBLAS_CONST enum CBLAS_TRANSPOSE TransA,
+                        OPENBLAS_CONST enum CBLAS_TRANSPOSE TransB,
+                        OPENBLAS_CONST blasint M, OPENBLAS_CONST blasint N,
+                        OPENBLAS_CONST blasint K, OPENBLAS_CONST float alpha,
+                        OPENBLAS_CONST float* A, OPENBLAS_CONST blasint lda,
+                        OPENBLAS_CONST float* B, OPENBLAS_CONST blasint ldb,
+                        OPENBLAS_CONST float beta, float* C,
+                        OPENBLAS_CONST blasint ldc);
+
+extern void cblas_sgemv(OPENBLAS_CONST enum CBLAS_ORDER order,
+                        OPENBLAS_CONST enum CBLAS_TRANSPOSE trans,
+                        OPENBLAS_CONST blasint m, OPENBLAS_CONST blasint n,
+                        OPENBLAS_CONST float alpha, OPENBLAS_CONST float* a,
+                        OPENBLAS_CONST blasint lda, OPENBLAS_CONST float* x,
+                        OPENBLAS_CONST blasint incx, OPENBLAS_CONST float beta,
+                        float* y, OPENBLAS_CONST blasint incy);
+
+// MLIR LIB
+extern void cblas_sbatch_matmul_mlir(
+    const enum CBLAS_ORDER Order, const enum CBLAS_TRANSPOSE TransA,
+    const enum CBLAS_TRANSPOSE TransB, const blasint P, const blasint M,
+    const blasint N, const blasint K, const float* A, const blasint lda,
+    const float* B, const blasint ldb, float* C, const blasint ldc);
+
+extern void cblas_sbatch_matmul_4d_mlir(
+    const enum CBLAS_ORDER Order, const enum CBLAS_TRANSPOSE TransA,
+    const enum CBLAS_TRANSPOSE TransB, const blasint Q, const blasint P,
+    const blasint M, const blasint N, const blasint K, const float* A,
+    const blasint lda, const float* B, const blasint ldb, float* C,
+    const blasint ldc);
+
+extern void cblas_sgemm_mlir(const enum CBLAS_ORDER Order,
+                             const enum CBLAS_TRANSPOSE TransA,
+                             const enum CBLAS_TRANSPOSE TransB, const blasint M,
+                             const blasint N, const blasint K,
+                             const float alpha, const float* A,
+                             const blasint lda, const float* B,
+                             const blasint ldb, const float beta, float* C,
+                             const blasint ldc);
+
+extern void cblas_sgemv_mlir(const enum CBLAS_ORDER Order,
+                             const enum CBLAS_TRANSPOSE TransA, const blasint M,
+                             const blasint N, const float alpha, const float* A,
+                             const blasint lda, const float* X,
+                             const blasint incX, const float beta, float* Y,
+                             const blasint incY);
+
+}  // extern "C"
+
+void __xla_cpu_runtime_KernelSelectorGEMM(bool trA, bool trB, const float* A,
+                                          const float* B, int m, int n, int k,
+                                          float alpha, float beta, float* C);
+
+void __xla_cpu_runtime_KernelSelectorBatch3D(bool trA, bool trB, const float* A,
+                                             const float* B, int P, int M,
+                                             int N, int K, float* C);
+
+void __xla_cpu_runtime_KernelSelectorGEMV(bool trA, const float* A,
+                                          const float* X, int M, int N,
+                                          float alpha, float beta, float* Y);
+
+void __xla_cpu_runtime_KernelSelectorGEMMMLIR(bool trA, bool trB,
+                                              const float* A, const float* B,
+                                              int m, int n, int k, float alpha,
+                                              float beta, float* C);
+
+void __xla_cpu_runtime_KernelSelectorBatch3DMLIR(bool trA, bool trB,
+                                                 const float* A, const float* B,
+                                                 int P, int M, int N, int K,
+                                                 float* C);
+
+void __xla_cpu_runtime_KernelSelectorBatch4DMLIR(bool trA, bool trB,
+                                                 const float* A, const float* B,
+                                                 int Q, int P, int M, int N,
+                                                 int K, float* C);
+
+void __xla_cpu_runtime_KernelSelectorGEMVMLIR(bool trA, const float* A,
+                                              const float* X, int M, int N,
+                                              float alpha, float beta,
+                                              float* Y);
+
+}  // namespace cpu
+}  // namespace xla
+
+#endif  // XLA_SERVICE_CPU_KERNEL_SELECTOR_H_
diff --git a/annc/service/cpu/xla/kernel_selector_ops_rewriter.cc b/annc/service/cpu/xla/kernel_selector_ops_rewriter.cc
new file mode 100644
index 0000000..16c8fa6
--- /dev/null
+++ b/annc/service/cpu/xla/kernel_selector_ops_rewriter.cc
@@ -0,0 +1,437 @@
+/* Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "kernel_selector_ops_rewriter.h"
+
+#include <fstream>
+#include <regex>
+#include <sstream>
+
+#include "xla/hlo/ir/dfs_hlo_visitor_with_default.h"
+#include "xla/hlo/ir/hlo_casting_utils.h"
+#include "xla/literal_util.h"
+#include "xla/service/cpu/cpu_runtime.h"
+
+namespace xla {
+namespace cpu {
+
+// Uncomment to get printed information about the sizes and the call selected.
+// #define PRINT_DEBUG
+
+#ifdef PRINT_DEBUG
+#include <iostream>
+#define DEBUG(x) std::cerr << x << "\n";
+#else
+#define DEBUG(x) \
+  do {           \
+  } while (0);
+#endif
+
+enum Operation { NONE, GEMV, GEMM, BATCH_MATMUL_3D, BATCH_MATMUL_4D };
+
+struct ParsedData {
+  std::vector<int> sizes;
+  std::string functionName;
+};
+
+// Parses line from the mapping file which look like (m,n,k) -> symbol
+ParsedData parseLine(const std::string& line) {
+  std::regex pattern(R"(\(((\d+,)*\d+)\) -> (.+))");
+  ParsedData data;
+  std::smatch matches;
+  if (std::regex_match(line, matches, pattern)) {
+    std::stringstream ss(matches[1]);
+    std::string token;
+    while (std::getline(ss, token, ',')) {
+      data.sizes.push_back(std::stoi(token));
+    }
+    data.functionName = matches[3];
+  } else {
+    XLA_VLOG_LINES(3, "KernelSelectorOpsRewriter::parseLine() : No match. \n");
+  }
+  return data;
+}
+
+std::map<std::vector<int>, std::string> sizesToSymbol = {
+    // GEMV
+    {{256, 256}, runtime::kKernelSelectorGEMVMLIRSymbolName},
+    {{128, 256}, runtime::kKernelSelectorGEMVMLIRSymbolName},
+    {{256, 64}, runtime::kKernelSelectorGEMVMLIRSymbolName},
+    // GEMM
+    {{6656, 8, 8}, runtime::kKernelSelectorGEMMMLIRSymbolName},
+    {{128, 1024, 416}, runtime::kKernelSelectorGEMMSymbolName},
+    {{128, 512, 1024}, runtime::kKernelSelectorGEMMSymbolName},
+    {{128, 256, 512}, runtime::kKernelSelectorGEMMSymbolName},
+    {{1536, 768, 3072}, runtime::kKernelSelectorGEMMSymbolName},
+    {{1536, 21128, 768}, runtime::kKernelSelectorGEMMSymbolName},
+    {{1536, 3072, 768}, runtime::kKernelSelectorGEMMSymbolName},
+    {{1536, 768, 768}, runtime::kKernelSelectorGEMMSymbolName},
+    // BATCH3D
+    {{512, 26, 4, 26}, runtime::kKernelSelectorBatch3DMLIRSymbolName},
+    {{512, 26, 26, 4}, runtime::kKernelSelectorBatch3DMLIRSymbolName},
+    // BATCH4D
+    {{4, 12, 384, 64, 384}, runtime::kKernelSelectorBatch4DMLIRSymbolName},
+    {{4, 12, 384, 384, 64}, runtime::kKernelSelectorBatch4DMLIRSymbolName}};
+
+const char* kernel_map_file = std::getenv("KERNEL_MAP_FILE");
+
+template <typename T1, typename T2>
+void fill_map_from_file(const char* map_file, std::map<T1, T2>& map) {
+  if (!map_file) {
+    XLA_VLOG_LINES(3, "NO MAP FILE\n");
+    return;
+  }
+
+  std::ifstream file(map_file);
+  if (!file.is_open()) {
+    std::string file_name(map_file);
+    XLA_VLOG_LINES(3,
+                   "KernelSelectorOpsRewriter::fill_map_from_file() : Cannot "
+                   "open file. \n");
+    return;
+  }
+
+  // Clear the map to prevent conflicts and unexpected
+  // behaviour due to default pre-filled values.
+  map.clear();
+
+  std::string line;
+  while (std::getline(file, line)) {
+    ParsedData data = parseLine(line);
+    if (!data.functionName.empty()) {
+      map[data.sizes] = data.functionName;
+    }
+  }
+
+  return;
+}
+
+class KernelSelectorOpsRewriterVisitor : public DfsHloRewriteVisitor {
+ private:
+  Operation getOperation(HloInstruction* instr) {
+    if (auto* dot = DynCast<HloDotInstruction>(instr)) {
+      auto batch_dims = dot->dot_dimension_numbers().lhs_batch_dimensions();
+      auto dims = dot->shape().dimensions();
+      if (batch_dims.size() == 1) {
+        return Operation::BATCH_MATMUL_3D;
+      }
+      if (batch_dims.size() == 2) {
+        return Operation::BATCH_MATMUL_4D;
+      }
+      if (dims.size() == 1) {
+        return Operation::GEMV;
+      }
+      if (batch_dims.empty()) {
+        return Operation::GEMM;
+      }
+    }
+    return Operation::NONE;
+  }
+
+  template <typename T>
+  HloInstruction* makeConstant(HloInstruction* op, T value) {
+    auto litteral = LiteralUtil::CreateR0<T>(value);
+    return op->AddInstruction(
+        HloInstruction::CreateConstant(std::move(litteral)));
+  }
+
+#ifdef PRINT_DEBUG
+  std::map<std::vector<int>, std::string> AllocatedGemmSizes;
+  std::map<std::vector<int>, std::string> AllocatedGemvSizes;
+  std::map<std::vector<int>, std::string> AllocatedBatchMatmul3DSizes;
+  std::map<std::vector<int>, std::string> AllocatedBatchMatmul4DSizes;
+#endif
+
+ public:
+  Status HandleDot(HloInstruction* dot) override {
+    Operation operation = getOperation(dot);
+    if (operation == Operation::NONE) {
+      return OkStatus();
+    }
+
+    // Collect all the operands for the CustomCall
+    switch (operation) {
+      case GEMM: {
+        auto dnums = dot->dot_dimension_numbers();
+        auto lhs_contracting_dims = dnums.lhs_contracting_dimensions();
+        auto rhs_contracting_dims = dnums.rhs_contracting_dimensions();
+
+        assert(lhs_contracting_dims.size() == 1);
+        assert(rhs_contracting_dims.size() == 1);
+
+        HloInstruction* trA = makeConstant(dot, lhs_contracting_dims[0] == 0);
+        HloInstruction* trB = makeConstant(dot, rhs_contracting_dims[0] == 1);
+
+        HloInstruction* alpha = makeConstant(dot, (float)1.0);
+        HloInstruction* beta = makeConstant(dot, (float)0.0);
+
+        HloInstruction* A = dot->operands()[0];
+        HloInstruction* B = dot->operands()[1];
+
+        int m = dot->shape().dimensions(0);
+        HloInstruction* M = makeConstant(dot, m);
+
+        int n = dot->shape().dimensions(1);
+        HloInstruction* N = makeConstant(dot, n);
+
+        int k = A->shape().dimensions(lhs_contracting_dims[0]);
+        HloInstruction* K = makeConstant(dot, k);
+
+        if (sizesToSymbol.find({m, n, k}) == sizesToSymbol.end()) {
+#ifdef PRINT_DEBUG
+          DEBUG("{m: " << m << ", n: " << n << ", k: " << k << "} -> "
+                       << "Is not on the map. The dot will not be replaced.");
+#endif
+          return OkStatus();
+        }
+
+        auto fun_name = sizesToSymbol[{m, n, k}];
+
+#ifdef PRINT_DEBUG
+        if (AllocatedGemmSizes.find({m, n, k}) == AllocatedGemmSizes.end()) {
+          AllocatedGemmSizes[{m, n, k}] = fun_name;
+          DEBUG("{m: " << m << ", n: " << n << ", k: " << k << "} -> "
+                       << fun_name);
+        }
+#endif
+
+        std::vector<HloInstruction*> operands = {trA, trB, A,     B,   M,
+                                                 N,   K,   alpha, beta};
+
+        HloInstruction* kernel_selector_call =
+            dot->AddInstruction(HloInstruction::CreateCustomCall(
+                dot->shape(), operands, "KernelSelector"));
+
+        // Add metadata
+        OpMetadata metadata = dot->metadata();
+        metadata.set_op_name(fun_name);
+        metadata.set_op_type(runtime::kKernelSelectorOperationGEMM);
+        kernel_selector_call->set_metadata(metadata);
+        TF_RETURN_IF_ERROR(ReplaceInstruction(dot, kernel_selector_call));
+
+        break;
+      }
+      case GEMV: {
+        auto dnums = dot->dot_dimension_numbers();
+        auto lhs_contracting_dims = dnums.lhs_contracting_dimensions();
+
+        assert(lhs_contracting_dims.size() == 1);
+
+        bool is_trA = lhs_contracting_dims[0] == 0;
+        HloInstruction* trA = makeConstant(dot, is_trA);
+
+        HloInstruction* alpha = makeConstant(dot, (float)1.0);
+        HloInstruction* beta = makeConstant(dot, (float)0.0);
+
+        HloInstruction* A = dot->operands()[0];
+        HloInstruction* X = dot->operands()[1];
+
+        int m = A->shape().dimensions(is_trA ? 1 : 0);
+        HloInstruction* M = makeConstant(dot, m);
+
+        int n = A->shape().dimensions(is_trA ? 0 : 1);
+        HloInstruction* N = makeConstant(dot, n);
+
+        // If (m,n) is not in the map, do not do anything.
+        if (sizesToSymbol.find({m, n}) == sizesToSymbol.end()) {
+#ifdef PRINT_DEBUG
+          DEBUG("{m: " << m << ", n: " << n << "} -> "
+                       << "Is not on the map. The dot will not be replaced.");
+#endif
+          return OkStatus();
+        }
+
+        auto fun_name = sizesToSymbol[{m, n}];
+
+#ifdef PRINT_DEBUG
+        if (AllocatedGemvSizes.find({m, n}) == AllocatedGemvSizes.end()) {
+          AllocatedGemvSizes[{m, n}] = fun_name;
+          DEBUG("{m: " << m << ", n: " << n << "} -> " << fun_name);
+        }
+#endif
+
+        std::vector<HloInstruction*> operands = {trA, A, X, M, N, alpha, beta};
+
+        HloInstruction* kernel_selector_call =
+            dot->AddInstruction(HloInstruction::CreateCustomCall(
+                dot->shape(), operands, "KernelSelector"));
+
+        // Add metadata
+        OpMetadata metadata = dot->metadata();
+        metadata.set_op_name(fun_name);
+        metadata.set_op_type(runtime::kKernelSelectorOperationGEMV);
+        kernel_selector_call->set_metadata(metadata);
+        TF_RETURN_IF_ERROR(ReplaceInstruction(dot, kernel_selector_call));
+
+        break;
+      }
+      case BATCH_MATMUL_3D: {
+        auto dnums = dot->dot_dimension_numbers();
+        auto lhs_contracting_dims = dnums.lhs_contracting_dimensions();
+        auto rhs_contracting_dims = dnums.rhs_contracting_dimensions();
+
+        assert(lhs_contracting_dims.size() == 1);
+        assert(rhs_contracting_dims.size() == 1);
+
+        HloInstruction* trA = makeConstant(dot, lhs_contracting_dims[0] == 1);
+        HloInstruction* trB = makeConstant(dot, rhs_contracting_dims[0] == 2);
+
+        HloInstruction* A = dot->operands()[0];
+        HloInstruction* B = dot->operands()[1];
+
+        int p = dot->shape().dimensions(0);
+        HloInstruction* P = makeConstant(dot, p);
+
+        int num_batch_dims = dnums.lhs_batch_dimensions_size();
+
+        int m = dot->shape().dimensions(num_batch_dims);
+        HloInstruction* M = makeConstant(dot, m);
+
+        int n = dot->shape().dimensions(num_batch_dims + 1);
+        HloInstruction* N = makeConstant(dot, n);
+
+        int k = A->shape().dimensions(lhs_contracting_dims[0]);
+        HloInstruction* K = makeConstant(dot, k);
+
+        // If (p,m,n,k) is not in the map, do not do anything.
+        if (sizesToSymbol.find({p, m, n, k}) == sizesToSymbol.end()) {
+#ifdef PRINT_DEBUG
+          DEBUG("{p: " << p << ", m: " << m << ", n: " << n << ", k: " << k
+                       << "} -> "
+                       << "  Is not on the map. The dot will not be replaced.");
+#endif
+          return OkStatus();
+        }
+
+        auto fun_name = sizesToSymbol[{p, m, n, k}];
+
+#ifdef PRINT_DEBUG
+        if (AllocatedBatchMatmul3DSizes.find({p, m, n, k}) ==
+            AllocatedBatchMatmul3DSizes.end()) {
+          AllocatedBatchMatmul3DSizes[{p, m, n, k}] = fun_name;
+          DEBUG("{p: " << p << ", m: " << m << ", n: " << n << ", k: " << k
+                       << "} -> " << fun_name);
+        }
+#endif
+
+        std::vector<HloInstruction*> operands = {trA, trB, A, B, P, M, N, K};
+
+        HloInstruction* kernel_selector_call =
+            dot->AddInstruction(HloInstruction::CreateCustomCall(
+                dot->shape(), operands, "KernelSelector"));
+
+        // Add metadata
+        OpMetadata metadata = dot->metadata();
+        metadata.set_op_name(fun_name);
+        metadata.set_op_type(runtime::kKernelSelectorOperationBATCH3D);
+        kernel_selector_call->set_metadata(metadata);
+        TF_RETURN_IF_ERROR(ReplaceInstruction(dot, kernel_selector_call));
+
+        break;
+      }
+      case BATCH_MATMUL_4D: {
+        auto dnums = dot->dot_dimension_numbers();
+        auto lhs_contracting_dims = dnums.lhs_contracting_dimensions();
+        auto rhs_contracting_dims = dnums.rhs_contracting_dimensions();
+
+        assert(lhs_contracting_dims.size() == 1);
+        assert(rhs_contracting_dims.size() == 1);
+
+        HloInstruction* trA = makeConstant(dot, lhs_contracting_dims[0] == 2);
+        HloInstruction* trB = makeConstant(dot, rhs_contracting_dims[0] == 3);
+
+        HloInstruction* A = dot->operands()[0];
+        HloInstruction* B = dot->operands()[1];
+
+        int q = dot->shape().dimensions(0);
+        HloInstruction* Q = makeConstant(dot, q);
+
+        int p = dot->shape().dimensions(1);
+        HloInstruction* P = makeConstant(dot, p);
+
+        int num_batch_dims = dnums.lhs_batch_dimensions_size();
+
+        int m = dot->shape().dimensions(num_batch_dims);
+        HloInstruction* M = makeConstant(dot, m);
+
+        int n = dot->shape().dimensions(num_batch_dims + 1);
+        HloInstruction* N = makeConstant(dot, n);
+
+        int k = A->shape().dimensions(lhs_contracting_dims[0]);
+        HloInstruction* K = makeConstant(dot, k);
+
+        // If (q,p,m,n,k) is not in the map, do not do anything.
+        if (sizesToSymbol.find({q, p, m, n, k}) == sizesToSymbol.end()) {
+#ifdef PRINT_DEBUG
+          DEBUG("{q: " << q << ", p: " << p << ", m: " << m << ", n: " << n
+                       << ", k: " << k << "} -> "
+                       << "Is not on the map. The dot will not be replaced.");
+#endif
+          return OkStatus();
+        }
+
+        auto fun_name = sizesToSymbol[{q, p, m, n, k}];
+
+#ifdef PRINT_DEBUG
+        if (AllocatedBatchMatmul4DSizes.find({q, p, m, n, k}) ==
+            AllocatedBatchMatmul4DSizes.end()) {
+          AllocatedBatchMatmul4DSizes[{q, p, m, n, k}] = fun_name;
+          DEBUG("{q: " << q << ", p: " << p << ", m: " << m << ", n: " << n
+                       << ", k: " << k << "} -> " << fun_name);
+        }
+#endif
+
+        std::vector<HloInstruction*> operands = {trA, trB, A, B, Q, P, M, N, K};
+
+        HloInstruction* kernel_selector_call =
+            dot->AddInstruction(HloInstruction::CreateCustomCall(
+                dot->shape(), operands, "KernelSelector"));
+
+        // Add metadata
+        OpMetadata metadata = dot->metadata();
+        metadata.set_op_name(fun_name);
+        metadata.set_op_type(runtime::kKernelSelectorOperationBATCH4D);
+        kernel_selector_call->set_metadata(metadata);
+        TF_RETURN_IF_ERROR(ReplaceInstruction(dot, kernel_selector_call));
+
+        break;
+      }
+      default:
+        DEBUG("No library funcion was selected.");
+        return OkStatus();
+    }
+
+    return OkStatus();
+  }
+};  // namespace cpu
+
+absl::StatusOr<bool> KernelSelectorOpsRewriter::Run(
+    HloModule* module,
+    const absl::flat_hash_set<absl::string_view>& execution_threads) {
+  XLA_VLOG_LINES(
+      3, "KernelSelectorOpsRewriter::Run(), before:\n" + module->ToString());
+
+  fill_map_from_file(kernel_map_file, sizesToSymbol);
+
+  KernelSelectorOpsRewriterVisitor visitor;
+  TF_ASSIGN_OR_RETURN(auto result,
+                      visitor.RunOnModule(module, execution_threads));
+  XLA_VLOG_LINES(
+      3, "KernelSelectorOpsRewriter::Run(), after:\n" + module->ToString());
+  return result;
+}
+
+}  // namespace cpu
+}  // namespace xla
diff --git a/annc/service/cpu/xla/kernel_selector_ops_rewriter.h b/annc/service/cpu/xla/kernel_selector_ops_rewriter.h
new file mode 100644
index 0000000..1abf074
--- /dev/null
+++ b/annc/service/cpu/xla/kernel_selector_ops_rewriter.h
@@ -0,0 +1,42 @@
+/* Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef XLA_SERVICE_CPU_KERNEL_SELECTOR_OPS_REWRITER_H_
+#define XLA_SERVICE_CPU_KERNEL_SELECTOR_OPS_REWRITER_H_
+
+#include "xla/hlo/ir/hlo_instructions.h"
+#include "xla/hlo/ir/hlo_module.h"
+#include "xla/service/hlo_pass_interface.h"
+
+namespace xla {
+namespace cpu {
+
+// This pass rewrites hlo.dot into custom calls.
+class KernelSelectorOpsRewriter : public HloModulePass {
+ public:
+  absl::string_view name() const override {
+    return "kernel-selector-ops-rewriter";
+  }
+
+  using HloPassInterface::Run;
+  absl::StatusOr<bool> Run(
+      HloModule* module,
+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;
+};
+
+}  // namespace cpu
+}  // namespace xla
+
+#endif  // XLA_SERVICE_CPU_KERNEL_SELECTOR_OPS_REWRITER_H_
diff --git a/annc/service/cpu/xla/libs/libXNNPACK.so b/annc/service/cpu/xla/libs/libXNNPACK.so
new file mode 120000
index 0000000..23ebe65
--- /dev/null
+++ b/annc/service/cpu/xla/libs/libXNNPACK.so
@@ -0,0 +1 @@
+XNNPACK/build/libXNNPACK.so
\ No newline at end of file
diff --git a/annc/service/cpu/xla/libs/libblas_920b_single_mlir.so b/annc/service/cpu/xla/libs/libblas_920b_single_mlir.so
new file mode 100755
index 0000000..838e0c7
Binary files /dev/null and b/annc/service/cpu/xla/libs/libblas_920b_single_mlir.so differ
diff --git a/annc/service/cpu/xla/libs/xnnpack.sh b/annc/service/cpu/xla/libs/xnnpack.sh
new file mode 100755
index 0000000..36b70b1
--- /dev/null
+++ b/annc/service/cpu/xla/libs/xnnpack.sh
@@ -0,0 +1,29 @@
+# Copyright 2025 Huawei. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+#!/bin/bash
+
+git clone https://github.com/google/XNNPACK
+cd XNNPACK
+# just to lock the commit and avoid unwanted surprises
+git checkout 92ed83bd07c3ba31366010db3ff8e132d8872416
+mkdir build
+cd build
+
+CFLAGS="-fPIC" cmake .. -DXNNPACK_BUILD_BENCHMARKS=OFF                         \
+                        -DXNNPACK_BUILD_TESTS=OFF                              \
+                        -DXNNPACK_LIBRARY_TYPE=shared                          \
+                        -DCMAKE_BUILD_TYPE=Release
+make -j32
diff --git a/annc/service/cpu/xla/xnnpack_ops.cc b/annc/service/cpu/xla/xnnpack_ops.cc
new file mode 100644
index 0000000..96c753d
--- /dev/null
+++ b/annc/service/cpu/xla/xnnpack_ops.cc
@@ -0,0 +1,77 @@
+/* Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#define XNN_LOG_LEVEL 4
+#include <xnnpack.h>
+#include <xnnpack/allocator.h>
+#include <xnnpack/buffer.h>
+#include <xnnpack/pack.h>
+
+#include "absl/base/attributes.h"
+
+namespace xla {
+namespace cpu {
+
+extern "C" {
+ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_XnnPackSoftMaxND(
+    const void* run_options_ptr, void* in, void* out, int64_t batch_size,
+    int64_t channels) {
+  // NB: run_options_ptr is ignored.
+  float* input = (float*)in;
+  float* output = (float*)out;
+
+  xnn_status status = xnn_initialize(nullptr /* allocator */);
+  if (status != xnn_status_success) {
+    std::cout << "failed to initialize XNNPACK";
+    return;
+  }
+
+  xnn_operator_t softmax_op = nullptr;
+  status = xnn_create_softmax_nc_f32(0 /* flags */, &softmax_op);
+  if (status != xnn_status_success || softmax_op == nullptr) {
+    std::cout << "failed to create SoftMax operator\n";
+    return;
+  }
+
+  status = xnn_reshape_softmax_nc_f32(softmax_op, channels, /* channels */
+                                      channels /* input stride */,
+                                      channels /* output stride */, batch_size,
+                                      /*threadpool=*/nullptr);
+  if (status != xnn_status_success) {
+    std::cout << "failed to reshape SoftMax operator";
+    return;
+  }
+
+  status = xnn_setup_softmax_nc_f32(softmax_op, input, output);
+  if (status != xnn_status_success) {
+    std::cout << "failed to setup SoftMax operator";
+    return;
+  }
+
+  status = xnn_run_operator(softmax_op, /*threadpool=*/nullptr);
+  if (status != xnn_status_success) {
+    std::cout << "failed to run SoftMax operator";
+    return;
+  }
+
+  xnn_delete_operator(softmax_op);
+
+  xnn_deinitialize();
+}
+
+}  // extern "C"
+
+}  // namespace cpu
+}  // namespace xla
diff --git a/annc/service/cpu/xla/xnnpack_ops.h b/annc/service/cpu/xla/xnnpack_ops.h
new file mode 100644
index 0000000..f0c0550
--- /dev/null
+++ b/annc/service/cpu/xla/xnnpack_ops.h
@@ -0,0 +1,34 @@
+/* Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef XLA_SERVICE_CPU_XNNPACK_OPS_H_
+#define XLA_SERVICE_CPU_XNNPACK_OPS_H_
+
+namespace xla {
+namespace cpu {
+
+extern "C" {
+
+extern void __xla_cpu_runtime_XnnPackSoftMaxND(const void* run_options_ptr,
+                                               void* in, void* out,
+                                               int64_t batch_size,
+                                               int64_t channels);
+
+}  // extern "C"
+
+}  // namespace cpu
+}  // namespace xla
+
+#endif  // XLA_SERVICE_CPU_XNNPACK_OPS_H_
diff --git a/annc/service/cpu/xla/xnnpack_ops_rewriter.cc b/annc/service/cpu/xla/xnnpack_ops_rewriter.cc
new file mode 100644
index 0000000..9dc45fc
--- /dev/null
+++ b/annc/service/cpu/xla/xnnpack_ops_rewriter.cc
@@ -0,0 +1,225 @@
+/*
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "xnnpack_ops_rewriter.h"
+
+#include "xla/hlo/ir/dfs_hlo_visitor_with_default.h"
+#include "xla/literal_comparison.h"
+#include "xla/literal_util.h"
+#include "xnnpack_pattern_utils.h"
+#include "xla/status_macros.h"
+
+namespace xla {
+namespace cpu {
+
+extern const char* const kCustomCallXnnPackSoftMax = "__xnnpack$softmax";
+
+namespace {
+namespace m = match;
+namespace pu = ::xla::cpu::xnnpack_pattern_utils_internal;
+
+bool IsNegInfConstScalar(const HloInstruction* const_instr) {
+  if (const_instr->opcode() != HloOpcode::kConstant) {
+    return false;
+  }
+  if (!ShapeUtil::IsEffectiveScalar(const_instr->shape())) {
+    return false;
+  }
+  auto value = LiteralUtil::GetFirstScalarLiteral(const_instr->literal());
+  return literal_comparison::Equal(
+             value, LiteralUtil::MinValue(const_instr->shape().element_type()))
+      .ok();
+}
+
+bool IsMaxReducerComputation(const HloComputation* comp) {
+  if (comp->root_instruction()->opcode() != HloOpcode::kMaximum) {
+    return false;
+  }
+  auto max_instr = comp->root_instruction();
+  const HloInstruction* p0 = comp->parameter_instruction(0);
+  const HloInstruction* p1 = comp->parameter_instruction(1);
+  const HloInstruction* max_p0 = max_instr->operand(0);
+  const HloInstruction* max_p1 = max_instr->operand(1);
+  return (max_p0 == p0 && max_p1 == p1) || (max_p1 == p0 && max_p0 == p1);
+}
+
+// Pattern to match any of Maximum(Reduce_max(...), -inf) or Reduce_max(...).
+auto MaxReduce(HloInstruction** instr) {
+  auto is_valid_reduce_max = [](const HloInstruction* reduce) {
+    HloComputation* reducer = reduce->to_apply();
+    return IsMaxReducerComputation(reducer) &&
+           (reduce->dimensions().size() == 1) &&
+           (reduce->operand(1)->opcode() == HloOpcode::kConstant) &&
+           IsNegInfConstScalar(reduce->operand(1));
+  };
+
+  return m::AnyOf<HloInstruction>(
+      m::Maximum().WithBinaryOperandsAnyOrder(
+          m::Reduce(instr).WithPredicate(is_valid_reduce_max).WithOneUse(),
+          pu::OptionalBroadcast(
+              m::Constant().WithPredicate(IsNegInfConstScalar))),
+      m::Reduce(instr).WithPredicate(is_valid_reduce_max).WithOneUse());
+}
+
+// Matches the softmax pattern with divide instruction as root node.
+// Here we pass 'instr' as root node and return the producer HloInstruction.
+// Tha axis on which softmax is applied is stored in 'axis'.
+std::optional<HloInstruction*> MatchSoftmax(HloInstruction* instr, int* axis) {
+  //
+  // producer
+  // |   \
+  // |  reduce_max or max(reduce_max)
+  // |     |
+  // |  reshape
+  // |     |
+  // |  broadcast
+  // |     |
+  // |  reshape
+  // |     |
+  // |  broadcast
+  // |   /
+  // subtract
+  // |
+  // exponential
+  // |   \
+  // |   Convert(optional)
+  // |     |
+  // |  reduce_sum
+  // |     |
+  // |   Convert(optional)
+  // |     |
+  // |  reshape
+  // |     |
+  // |   Convert(optional)
+  // |     |
+  // |  broadcast
+  // |     |
+  // |  reshape
+  // |     |
+  // |  broadcast
+  // |   /
+  // divide  // (instr parameter)
+  //
+
+  // This matcher covers the most common SoftMax patterns we have encountered
+  // in real-life models.
+  HloInstruction* left_exponential;
+  HloInstruction* right_exponential;
+  HloInstruction* left_producer;
+  HloInstruction* reduce_sum;
+  HloInstruction* reduce_max;
+  HloInstruction* reduce_instr;
+
+  // Lower diamond
+  if (!Match(instr,
+             m::Divide(
+                 m::Exp(&left_exponential, m::Op()),
+                 m::Broadcast(m::Reshape(m::Broadcast(
+                     pu::OptionalConvert(m::Reshape(pu::OptionalConvert(
+                         m::Reduce(&reduce_sum,
+                                   pu::OptionalConvert(
+                                       m::Exp(&right_exponential, m::Op())),
+                                   m::ConstantScalar(0))
+                             .WithPredicate([](const HloInstruction* reduce) {
+                               HloComputation* reducer = reduce->to_apply();
+                               return (reducer->root_instruction()->opcode() ==
+                                           HloOpcode::kAdd &&
+                                       reduce->dimensions().size() == 1);
+                             })
+                             .WithOneUse()))))))))) {
+    return std::nullopt;
+  }
+
+  if (left_exponential != right_exponential ||
+      left_exponential->user_count() != 2) {
+    return std::nullopt;
+  }
+
+  // Upper diamond
+  if (!Match(left_exponential->mutable_operand(0),
+             m::Subtract(m::Op(&left_producer),
+                         m::Broadcast(m::Reshape(m::Broadcast(
+                                          m::Reshape(m::Op(&reduce_instr)))))
+                             .WithOneUse())
+                 .WithOneUse())) {
+    return std::nullopt;
+  }
+
+  // Match the reduce max.
+  if (!Match(reduce_instr, MaxReduce(&reduce_max))) {
+    return std::nullopt;
+  }
+
+  if (left_producer != reduce_max->operand(0) ||
+      left_producer->user_count() != 2) {
+    return std::nullopt;
+  }
+
+  if (reduce_sum->dimensions()[0] != reduce_max->dimensions()[0]) {
+    return std::nullopt;
+  }
+
+  *axis = reduce_sum->dimensions()[0];
+
+  return left_producer;
+}
+
+}  // namespace
+
+class XnnPackOpsRewriterVisitor : public DfsHloRewriteVisitor {
+ public:
+  absl::Status HandleDivide(HloInstruction* divide_instr) override {
+    if (divide_instr->HasControlDependencies()) {
+      return absl::OkStatus();
+    }
+    if (!pu::IsSupportedType(divide_instr->shape().element_type())) {
+      return absl::OkStatus();
+    }
+    int axis = -1;
+    std::optional<HloInstruction*> producer = MatchSoftmax(divide_instr, &axis);
+    if (producer == std::nullopt) {
+      return absl::OkStatus();
+    }
+
+    const Shape& output_shape = divide_instr->shape();
+    int softmax_dims = output_shape.dimensions().size();
+    if (softmax_dims < 2) {
+      XLA_VLOG_LINES(3, "Found SoftMax with " + std::to_string(softmax_dims) +
+                            " dims, which is not supported\n");
+      return absl::OkStatus();
+    }
+
+    HloInstruction* softmax_call =
+        divide_instr->AddInstruction(HloInstruction::CreateCustomCall(
+            output_shape, {producer.value()}, kCustomCallXnnPackSoftMax));
+    TF_RETURN_IF_ERROR(ReplaceInstruction(divide_instr, softmax_call));
+
+    return absl::OkStatus();
+  }
+};
+
+absl::StatusOr<bool> XnnPackOpsRewriter::Run(
+    HloModule* module,
+    const absl::flat_hash_set<absl::string_view>& execution_threads) {
+  XLA_VLOG_LINES(3,
+                 "XnnPackOpsRewriter::Run(), before:\n" + module->ToString());
+  XnnPackOpsRewriterVisitor visitor;
+  TF_ASSIGN_OR_RETURN(auto result,
+                      visitor.RunOnModule(module, execution_threads));
+  XLA_VLOG_LINES(3, "XnnPackOpsRewriter::Run(), after:\n" + module->ToString());
+  return result;
+}
+
+}  // namespace cpu
+}  // namespace xla
diff --git a/annc/service/cpu/xla/xnnpack_ops_rewriter.h b/annc/service/cpu/xla/xnnpack_ops_rewriter.h
new file mode 100644
index 0000000..11b8401
--- /dev/null
+++ b/annc/service/cpu/xla/xnnpack_ops_rewriter.h
@@ -0,0 +1,44 @@
+/* Copyright 2025 Huawei. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef XLA_SERVICE_CPU_XNNPACK_OPS_REWRITER_H_
+#define XLA_SERVICE_CPU_XNNPACK_OPS_REWRITER_H_
+
+#include <optional>
+
+#include "absl/algorithm/container.h"
+#include "xla/hlo/ir/hlo_instructions.h"
+#include "xla/hlo/ir/hlo_module.h"
+#include "xla/service/hlo_pass_interface.h"
+
+namespace xla {
+namespace cpu {
+
+extern const char* const kCustomCallXnnPackSoftMax;
+
+class XnnPackOpsRewriter : public HloModulePass {
+ public:
+  absl::string_view name() const override { return "xnnpack-ops-rewriter"; }
+
+  using HloPassInterface::Run;
+  absl::StatusOr<bool> Run(
+      HloModule* module,
+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;
+};
+
+}  // namespace cpu
+}  // namespace xla
+
+#endif  // XLA_SERVICE_CPU_XNNPACK_OPS_REWRITER_H_
diff --git a/annc/service/cpu/xla/xnnpack_pattern_utils.h b/annc/service/cpu/xla/xnnpack_pattern_utils.h
new file mode 100644
index 0000000..8914dfb
--- /dev/null
+++ b/annc/service/cpu/xla/xnnpack_pattern_utils.h
@@ -0,0 +1,62 @@
+/*
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef XLA_SERVICE_CPU_XNNPACK_PATTERN_UTILS_H_
+#define XLA_SERVICE_CPU_XNNPACK_PATTERN_UTILS_H_
+
+#include "xla/hlo/ir/hlo_instruction.h"
+#include "xla/hlo/ir/hlo_instructions.h"
+#include "xla/service/pattern_matcher.h"
+
+namespace xla {
+namespace cpu {
+
+namespace xnnpack_pattern_utils_internal {
+namespace m = match;
+
+template <typename Pattern>
+auto OptionalConvert(Pattern pattern) {
+  return m::AnyOf<HloInstruction>(m::Convert(pattern), std::move(pattern));
+}
+
+template <typename Pattern>
+auto OptionalBroadcast(Pattern pattern) {
+  return m::AnyOf<HloInstruction>(m::Broadcast(pattern), std::move(pattern));
+}
+
+// Simplified from upstream XLA.
+inline bool IsSupportedType(xla::PrimitiveType dtype) { return dtype == F32; }
+
+template <typename Pattern>
+inline auto SupportedConvert(Pattern pattern) {
+  auto supported_convert = [](const HloInstruction* instr) -> bool {
+    return IsSupportedType(instr->shape().element_type()) &&
+           IsSupportedType(instr->operand(0)->shape().element_type());
+  };
+  return m::Convert(pattern).WithPredicate(supported_convert);
+}
+
+template <typename Pattern>
+inline auto SupportedConvert(HloInstruction** convert, Pattern pattern) {
+  auto supported_convert = [](const HloInstruction* instr) -> bool {
+    return IsSupportedType(instr->shape().element_type()) &&
+           IsSupportedType(instr->operand(0)->shape().element_type());
+  };
+  return m::Convert(convert, pattern).WithPredicate(supported_convert);
+}
+}  // namespace xnnpack_pattern_utils_internal
+}  // namespace cpu
+}  // namespace xla
+
+#endif  // XLA_SERVICE_CPU_XNNPACK_PATTERN_UTILS_H_
diff --git a/build.sh b/build.sh
new file mode 100755
index 0000000..37875d9
--- /dev/null
+++ b/build.sh
@@ -0,0 +1,86 @@
+# Copyright 2025 Huawei. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+#!/bin/bash
+
+## Use these variables if bazel or go are not on the PATH.
+BAZEL=""
+GO=""
+
+ANNC_BASE="$HOME/tools"
+if [ ! -d "${ANNC_BASE/ANNC}" ]; then
+  echo "Please set ANNC_BASE in this script to point to the base directory of ANNC"
+fi
+
+# Adjust as appropriate
+export CC=/usr/bin/gcc
+export CXX=/usr/bin/g++
+export LD_LIBRARY_PATH=/lib64
+
+PATH=$GO:$BAZEL:$PATH
+export PATH
+
+# Check for bazel.
+if ! command -v bazel >/dev/null 2>&1; then
+  echo "Please add bazel to PATH."
+  echo "Exiting"
+  exit -1
+fi
+
+# Check for go.
+if ! command -v go >/dev/null 2>&1; then
+  echo "Please add go to PATH."
+  echo "Exiting"
+  exit -1
+fi
+
+ANNC="$ANNC_BASE/ANNC"
+XNNPACK_BASE="$ANNC/annc/service/cpu/xla/libs"
+XNNPACK_DIR="$XNNPACK_BASE/XNNPACK"
+
+# At the moment XNNPAK is cloned and compiled by a script. The script is only
+# run if the directory containing XNNPACK does not exist.
+if [ ! -d "${XNNPACK_DIR}" ]; then
+  cd $XNNPACK_BASE
+  ./xnnpack.sh
+  cd -
+else
+  echo "The directory XNNPACK already exists. Skipping cloning xnnpack."
+fi
+
+# This is needed so files included by us which are used in xla can be found.
+CPLUS_INCLUDE_PATH+="$ANNC/annc/service/cpu/xla/:"
+
+# This is the location where the files included are in the main repo
+# Ideally the XNNPACK repository should be downloaded and compiled by bazel so
+# the directories needed should be handled automatically by bazel
+CPLUS_INCLUDE_PATH+="$XNNPACK_DIR/:"
+CPLUS_INCLUDE_PATH+="$XNNPACK_DIR/include/:"
+CPLUS_INCLUDE_PATH+="$XNNPACK_DIR/src/:"
+CPLUS_INCLUDE_PATH+="$XNNPACK_DIR/build/pthreadpool-source/include/:"
+export CPLUS_INCLUDE_PATH
+
+# Changing the value of ACTION_ENV should trigger full compilation
+ACTION_ENV="baila=548"
+
+bazel --output_user_root=./output                                              \
+      build -c opt                                                             \
+      --verbose_failures                                                       \
+      --action_env=$ACTION_ENV                                                 \
+      --define tflite_with_xnnpack=false                                       \
+      annc/service/cpu:libannc.so                                              \
+      --copt=-DANNC_ENABLED_OPENBLAS                                           \
+      --jobs 32
+
diff --git a/install/tfserver/xla/xla.sh b/install/tfserver/xla/xla.sh
old mode 100644
new mode 100755
diff --git a/install/xla/BUILD.patch b/install/xla/BUILD.patch
new file mode 100644
index 0000000..0b7598e
--- /dev/null
+++ b/install/xla/BUILD.patch
@@ -0,0 +1,71 @@
+diff --git a/xla/service/cpu/BUILD b/xla/service/cpu/BUILD
+index f882ee2210..1c053f0f9c 100644
+--- a/xla/service/cpu/BUILD
++++ b/xla/service/cpu/BUILD
+@@ -199,6 +199,7 @@ cc_library(
+     srcs = ["cpu_compiler.cc"],
+     hdrs = ["cpu_compiler.h"],
+     copts = tsl_copts(),
++    visibility = ["//visibility:public"],
+     deps = [
+         ":buffer_info_util",
+         ":compiler_functor",
+@@ -510,6 +511,7 @@ cc_library(
+     ],
+     hdrs = ["simple_orc_jit.h"],
+     copts = if_enable_acl(["-DXLA_CPU_USE_ACL=1"]) + tsl_copts(),
++    visibility = ["//visibility:public"],
+     deps = [
+         ":compiler_functor",
+         ":cpu_runtime",
+@@ -553,6 +555,7 @@ cc_library(
+     hdrs = ["runtime_lightweight_check.h"],
+     compatible_with = get_compatible_with_portable(),
+     copts = runtime_copts(),
++    visibility = ["//visibility:public"],
+ )
+
+ cc_library(
+@@ -641,6 +644,7 @@ cc_library(
+         "ir_emitter.h",
+     ],
+     copts = tsl_copts(),
++    visibility = ["//visibility:public"],
+     deps = [
+         ":backend_config_proto_cc",
+         ":cpu_options",
+@@ -873,6 +877,7 @@ cc_library(
+         "xfeed_manager.h",
+     ],
+     copts = runtime_copts(),
++    visibility = ["//visibility:public"],
+     deps = [
+         "//xla:executable_run_options",
+         "//xla:refcounting_hash_map",
+
+diff --git a/xla/service/BUILD b/xla/service/BUILD
+index 1a0836c9f3..f7bbe16f5a 100644
+--- a/xla/service/BUILD
++++ b/xla/service/BUILD
+@@ -1986,6 +1986,7 @@ cc_library(
+     hdrs = [
+         "hlo_creation_utils.h",
+     ],
++    visibility = ["//visibility:public"],
+     deps = [
+         ":hlo_module_config",
+         ":shape_inference",
+
+diff --git a/xla/BUILD b/xla/BUILD
+index b4b1996064..9de937be7b 100644
+--- a/xla/BUILD
++++ b/xla/BUILD
+@@ -648,7 +648,7 @@ cc_library(
+     name = "literal_comparison",
+     srcs = ["literal_comparison.cc"],
+     hdrs = ["literal_comparison.h"],
+-    visibility = [":friends"],
++    visibility = ["//visibility:public"],
+     deps = [
+         ":error_spec",
+         ":literal",
diff --git a/install/xla/cpu_compiler.patch b/install/xla/cpu_compiler.patch
new file mode 100644
index 0000000..bc905fe
--- /dev/null
+++ b/install/xla/cpu_compiler.patch
@@ -0,0 +1,50 @@
+diff --git a/xla/service/cpu/cpu_compiler.cc b/xla/service/cpu/cpu_compiler.cc
+index 371c836c4a..14c9429165 100644
+--- a/xla/service/cpu/cpu_compiler.cc
++++ b/xla/service/cpu/cpu_compiler.cc
+@@ -241,6 +241,9 @@ limitations under the License.
+ #include "xla/service/cpu/onednn_rewriter.h"
+ #endif
+ 
++#include <annc/xnnpack_ops_rewriter.h>
++#include <annc/kernel_selector_ops_rewriter.h>
++
+ namespace {
+ 
+ // We need to explicitly load all the dialects we will involved in emitting the
+@@ -262,6 +265,8 @@ void LoadMLIRDialects(mlir::MLIRContext& context) {
+ xla::cpu::HloXlaRuntimePipelineOptions GetHloXlaRuntimePipelineOptions(
+     llvm::Triple target_triple, llvm::StringRef cpu_name) {
+   xla::cpu::HloXlaRuntimePipelineOptions options;
++  options.use_kernel_selector =
++      xla::GetDebugOptionsFromFlags().xla_cpu_use_kernel_selector();
+   options.enable_tiling_and_fusion =
+       xla::GetDebugOptionsFromFlags().xla_cpu_enable_mlir_tiling_and_fusion();
+   if (xla::GetDebugOptionsFromFlags().xla_cpu_enable_custom_matmul_tiling()) {
+@@ -689,6 +694,12 @@ Status CpuCompiler::RunHloPassesThroughLayoutAssn(
+   pipeline.AddPass<BatchDotSimplification>();
+   pipeline.AddPass<DotDecomposer>();
+ 
++  // Rewrite to custom calls with XNNPACK targets.
++  bool enable_xnnpack =
++      xla::GetDebugOptionsFromFlags().xla_cpu_enable_xnnpack();
++  if (enable_xnnpack)
++    pipeline.AddPass<XnnPackOpsRewriter>();
++
+   // Rewrite to custom calls with target as oneDNN library calls.
+ #if defined(INTEL_MKL) && defined(ENABLE_ONEDNN_V3)
+   // AOT compiled code runs in single thread.
+@@ -890,6 +901,13 @@ Status CpuCompiler::RunHloPassesAfterLayoutAssn(
+ 
+   pipeline.AddPass<ReshapeDecomposer>();
+ 
++  bool use_kernel_selector =
++      xla::GetDebugOptionsFromFlags().xla_cpu_use_kernel_selector();
++  if (use_kernel_selector) {
++    // This pass rewrites hlo.dot into custom calls.
++    pipeline.AddPass<KernelSelectorOpsRewriter>();
++  }
++
+   // Add a fusion pass now that layout assignment is done.
+   bool may_duplicate =
+       xla::GetDebugOptionsFromFlags().xla_cpu_enable_duplicate_fusion();
diff --git a/install/xla/cpu_runtime.cc.patch b/install/xla/cpu_runtime.cc.patch
new file mode 100644
index 0000000..e9f14f8
--- /dev/null
+++ b/install/xla/cpu_runtime.cc.patch
@@ -0,0 +1,51 @@
+diff --git a/xla/service/cpu/cpu_runtime.cc b/xla/service/cpu/cpu_runtime.cc
+index 84879eaf0f..f29b02e8b1 100644
+--- a/xla/service/cpu/cpu_runtime.cc
++++ b/xla/service/cpu/cpu_runtime.cc
+@@ -34,6 +34,9 @@ limitations under the License.
+ #include "absl/strings/str_format.h"
+ #include "absl/strings/str_join.h"
+ #include "absl/synchronization/mutex.h"
++#include "tsl/platform/logging.h"
++#include "tsl/platform/status.h"
++#include "tsl/profiler/lib/traceme.h"
+ #include "xla/executable_run_options.h"
+ #include "xla/layout_util.h"
+ #include "xla/primitive_util.h"
+@@ -46,9 +49,6 @@ limitations under the License.
+ #include "xla/statusor.h"
+ #include "xla/stream_executor/device_memory.h"
+ #include "xla/stream_executor/stream_executor.h"
+-#include "tsl/platform/logging.h"
+-#include "tsl/platform/status.h"
+-#include "tsl/profiler/lib/traceme.h"
+ 
+ namespace xla {
+ namespace cpu {
+@@ -149,6 +149,26 @@ extern const char* const kPartitionIdSymbolName =
+ extern const char* const kReplicaIdSymbolName = "__xla_cpu_runtime_ReplicaId";
+ extern const char* const kOneDnnMatMulSymbolName =
+     "__xla_cpu_runtime_OneDnnMatMul";
++extern const char* const kXnnPackSoftMaxNDSymbolName =
++    "__xla_cpu_runtime_XnnPackSoftMaxND";
++extern const char* const kKernelSelectorGEMVSymbolName =
++    "__xla_cpu_runtime_KernelSelectorGEMV";
++extern const char* const kKernelSelectorGEMMSymbolName =
++    "__xla_cpu_runtime_KernelSelectorGEMM";
++extern const char* const kKernelSelectorBatch3DSymbolName =
++    "__xla_cpu_runtime_KernelSelectorBatch3D";
++extern const char* const kKernelSelectorGEMVMLIRSymbolName =
++    "__xla_cpu_runtime_KernelSelectorGEMVMLIR";
++extern const char* const kKernelSelectorGEMMMLIRSymbolName =
++    "__xla_cpu_runtime_KernelSelectorGEMMMLIR";
++extern const char* const kKernelSelectorBatch3DMLIRSymbolName =
++    "__xla_cpu_runtime_KernelSelectorBatch3DMLIR";
++extern const char* const kKernelSelectorBatch4DMLIRSymbolName =
++    "__xla_cpu_runtime_KernelSelectorBatch4DMLIR";
++extern const char* const kKernelSelectorOperationGEMV = "GEMV";
++extern const char* const kKernelSelectorOperationGEMM = "GEMM";
++extern const char* const kKernelSelectorOperationBATCH3D = "BATCH3D";
++extern const char* const kKernelSelectorOperationBATCH4D = "BATCH4D";
+ 
+ namespace {
+ 
diff --git a/install/xla/cpu_runtime.h.patch b/install/xla/cpu_runtime.h.patch
new file mode 100644
index 0000000..5143ba4
--- /dev/null
+++ b/install/xla/cpu_runtime.h.patch
@@ -0,0 +1,25 @@
+diff --git a/xla/service/cpu/cpu_runtime.h b/xla/service/cpu/cpu_runtime.h
+index e483b8c9e8..467022460e 100644
+--- a/xla/service/cpu/cpu_runtime.h
++++ b/xla/service/cpu/cpu_runtime.h
+@@ -85,6 +85,20 @@ extern const char* const kTracingStartSymbolName;
+ extern const char* const kTracingEndSymbolName;
+ extern const char* const kAllToAllSymbolName;
+ extern const char* const kOneDnnMatMulSymbolName;
++extern const char* const kXnnPackSoftMaxNDSymbolName;
++extern const char* const kKernelSelectorGEMVSymbolName;
++extern const char* const kKernelSelectorGEMMSymbolName;
++extern const char* const kKernelSelectorBatch3DSymbolName;
++extern const char* const kKernelSelectorGEMVMLIRSymbolName;
++extern const char* const kKernelSelectorGEMMMLIRSymbolName;
++extern const char* const kKernelSelectorBatch3DMLIRSymbolName;
++extern const char* const kKernelSelectorBatch4DMLIRSymbolName;
++
++// Kernel selector operation names.
++extern const char* const kKernelSelectorOperationGEMV;
++extern const char* const kKernelSelectorOperationGEMM;
++extern const char* const kKernelSelectorOperationBATCH3D;
++extern const char* const kKernelSelectorOperationBATCH4D;
+ 
+ // All symbol names for XLA CPU runtime functions need to start with this
+ // prefix.
diff --git a/install/xla/debug_options_flags.cc.patch b/install/xla/debug_options_flags.cc.patch
new file mode 100644
index 0000000..8ea6869
--- /dev/null
+++ b/install/xla/debug_options_flags.cc.patch
@@ -0,0 +1,32 @@
+diff --git a/xla/debug_options_flags.cc b/xla/debug_options_flags.cc
+index 7982ab2590..e2706e6fda 100644
+--- a/xla/debug_options_flags.cc
++++ b/xla/debug_options_flags.cc
+@@ -171,6 +171,10 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {
+   opts.set_xla_cpu_matmul_tiling_k_dim(8);
+   opts.set_xla_cpu_enable_mlir_fusion_outlining(true);
+   opts.set_xla_cpu_enable_experimental_deallocation(true);
++  opts.set_xla_cpu_enable_xnnpack(false);
++
++  // Kernel Selector
++  opts.set_xla_cpu_use_kernel_selector(false);
+
+   opts.set_xla_partitioning_algorithm(
+       DebugOptions::PARTITIONING_ALGORITHM_NOOP);
+@@ -1143,6 +1147,16 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,
+                     &DebugOptions::set_xla_gpu_enable_latency_hiding_scheduler),
+                 debug_options->xla_gpu_enable_latency_hiding_scheduler(),
+                 "Enable latency-hiding scheduler for XLA:GPU"));
++  flag_list->push_back(tsl::Flag(
++      "xla_cpu_enable_xnnpack",
++      bool_setter_for(&DebugOptions::set_xla_cpu_enable_xnnpack),
++      debug_options->xla_cpu_enable_xnnpack(),
++      "Enable XNNPACK ops rewriter."));
++  flag_list->push_back(
++     tsl::Flag("xla_cpu_use_kernel_selector",
++      bool_setter_for(&DebugOptions::set_xla_cpu_use_kernel_selector),
++      debug_options->xla_cpu_use_kernel_selector(),
++      "Replace dot with custom call to libraries."));
+   flag_list->push_back(tsl::Flag(
+       "xla_gpu_enable_analytical_latency_estimator",
+       bool_setter_for(
\ No newline at end of file
diff --git a/install/xla/hlo_xla_runtime_pipeline.h.patch b/install/xla/hlo_xla_runtime_pipeline.h.patch
new file mode 100644
index 0000000..e21e615
--- /dev/null
+++ b/install/xla/hlo_xla_runtime_pipeline.h.patch
@@ -0,0 +1,12 @@
+diff --git a/xla/service/cpu/hlo_xla_runtime_pipeline.h b/xla/service/cpu/hlo_xla_runtime_pipeline.h
+index b77436c165..3fb94cca82 100644
+--- a/xla/service/cpu/hlo_xla_runtime_pipeline.h
++++ b/xla/service/cpu/hlo_xla_runtime_pipeline.h
+@@ -35,6 +35,7 @@ struct HloXlaRuntimePipelineOptions {
+   bool remove_copies_to_outparams = true;
+   bool sparse_bufferization = true;
+   bool experimental_deallocation = false;
++  bool use_kernel_selector = false;
+   bool enable_avx2 = true;
+   // Accelerate sparse computations with CUDA threading.
+   // This is an experimental feature, so off by default.
diff --git a/install/xla/ir_emitter.cc.patch b/install/xla/ir_emitter.cc.patch
new file mode 100644
index 0000000..c369b21
--- /dev/null
+++ b/install/xla/ir_emitter.cc.patch
@@ -0,0 +1,205 @@
+diff --git a/xla/service/cpu/ir_emitter.cc b/xla/service/cpu/ir_emitter.cc
+index 7013a45f1e..0043e144f6 100644
+--- a/xla/service/cpu/ir_emitter.cc
++++ b/xla/service/cpu/ir_emitter.cc
+@@ -46,6 +46,9 @@ limitations under the License.
+ #include "llvm/IR/IntrinsicsX86.h"
+ #include "llvm/IR/LLVMContext.h"
+ #include "llvm/IR/Value.h"
++#include "tsl/lib/math/math_util.h"
++#include "tsl/platform/errors.h"
++#include "tsl/platform/logging.h"
+ #include "xla/hlo/ir/hlo_casting_utils.h"
+ #include "xla/hlo/ir/hlo_instruction.h"
+ #include "xla/hlo/ir/hlo_instructions.h"
+@@ -63,6 +66,8 @@ limitations under the License.
+ #include "xla/service/cpu/ir_emission_utils.h"
+ #include "xla/service/cpu/ir_function.h"
+ #include "xla/service/cpu/parallel_loop_emitter.h"
++#include <xnnpack_ops.h>
++#include <xnnpack_ops_rewriter.h>
+ #include "xla/service/elemental_ir_emitter.h"
+ #include "xla/service/llvm_ir/buffer_assignment_util.h"
+ #include "xla/service/llvm_ir/dynamic_update_slice_util.h"
+@@ -77,9 +82,6 @@ limitations under the License.
+ #include "xla/util.h"
+ #include "xla/window_util.h"
+ #include "xla/xla_data.pb.h"
+-#include "tsl/lib/math/math_util.h"
+-#include "tsl/platform/errors.h"
+-#include "tsl/platform/logging.h"
+ 
+ #if defined(INTEL_MKL) && defined(ENABLE_ONEDNN_V3)
+ #include "xla/service/cpu/onednn_memory_util.h"
+@@ -2471,6 +2473,155 @@ Status IrEmitter::HandleOneDnnMatMul(HloInstruction* custom_call) {
+ }
+ #endif  // INTEL_MKL && ENABLE_ONEDNN_V3
+ 
++Status IrEmitter::HandleXnnPackSoftMax(HloInstruction* hlo) {
++  const HloInstruction* input = hlo->operand(0);
++  Shape shape = input->shape();
++
++  TF_RETURN_IF_ERROR(EmitTargetAddressForOp(hlo));
++  TF_RET_CHECK(input->shape().element_type() == F32);
++  TF_RET_CHECK(shape.rank() >= 2);
++
++  TF_ASSIGN_OR_RETURN(const BufferAllocation::Slice input_values_slice,
++                      assignment_.GetUniqueSlice(hlo->operand(0), {}));
++  TF_ASSIGN_OR_RETURN(const BufferAllocation::Slice out_values_slice,
++                      assignment_.GetUniqueSlice(hlo, {}));
++
++  llvm::Value* values_ptr = EmitBufferPointer(input_values_slice, shape);
++  llvm::Value* out_values_ptr = EmitBufferPointer(out_values_slice, shape);
++
++  // Flatten the batches into a single dimension.
++  int channels = shape.dimensions(shape.rank() - 1);
++  int batch_size = 1;
++  for (int i = 0; i < shape.rank() - 1; i++)
++    batch_size = batch_size * shape.dimensions(i);
++
++  EmitCallToFunc(runtime::kXnnPackSoftMaxNDSymbolName,
++                 {/*run_options=*/GetExecutableRunOptionsArgument(),
++                  /*input*/ values_ptr,
++                  /*output*/ out_values_ptr,
++                  /*batch_size*/ b_.getInt64(batch_size),
++                  /*channels*/ b_.getInt64(channels)},
++                 b_.getVoidTy());
++
++  return OkStatus();
++}
++
++Status IrEmitter::HandleKernelSelector(HloInstruction* custom_call) {
++  OpMetadata metadata = custom_call->metadata();
++
++  bool isGEMV = (metadata.op_type() == runtime::kKernelSelectorOperationGEMV);
++  bool isGEMM = (metadata.op_type() == runtime::kKernelSelectorOperationGEMM);
++  bool isBATCHMATMUL3D =
++      (metadata.op_type() == runtime::kKernelSelectorOperationBATCH3D);
++  bool isBATCHMATMUL4D =
++      (metadata.op_type() == runtime::kKernelSelectorOperationBATCH4D);
++  bool isBATCHMATMUL = isBATCHMATMUL3D | isBATCHMATMUL4D;
++
++  int operand = 0;
++  std::vector<llvm::Value*> arguments;
++
++  //  |               arguments               |
++  //  |  gemm  |  batch3d |  batch4d | gemv   |
++  //  -----------------------------------------
++  //  |  trA   |  trA     |  trA     |  trA   |
++  //  |  trB   |  trB     |  trB     |        |
++  //  |  A     |  A       |  A       |  A     |
++  //  |  B     |  B       |  B       |  X     |
++  //  |        |          |  Q       |        |
++  //  |        |  P       |  P       |        |
++  //  |  M     |  M       |  M       |  M     |
++  //  |  N     |  N       |  N       |  N     |
++  //  |  K     |  K       |  K       |        |
++  //  |  alpha |          |          |  alpha |
++  //  |  beta  |          |          |  beta  |
++
++  // trA
++  HloInstruction const* trA = custom_call->operand(operand++);
++  bool tranA = trA->literal().Get<bool>({});
++  arguments.push_back(b_.getInt1(tranA));
++
++  if (isGEMM || isBATCHMATMUL) {
++    // trB
++    HloInstruction const* trB = custom_call->operand(operand++);
++    bool tranB = trB->literal().Get<bool>({});
++    arguments.push_back(b_.getInt1(tranB));
++  }
++
++  // A
++  HloInstruction const* A = custom_call->operand(operand++);
++  TF_ASSIGN_OR_RETURN(const BufferAllocation::Slice a_slice,
++                      assignment_.GetUniqueSlice(A, {}));
++  llvm::Value* A_ptr = EmitBufferPointer(a_slice, A->shape());
++  arguments.push_back(A_ptr);
++
++  // B (or X in GEMV)
++  HloInstruction const* B = custom_call->operand(operand++);
++  TF_ASSIGN_OR_RETURN(const BufferAllocation::Slice b_slice,
++                      assignment_.GetUniqueSlice(B, {}));
++  llvm::Value* B_ptr = EmitBufferPointer(b_slice, B->shape());
++  arguments.push_back(B_ptr);
++
++  if (isBATCHMATMUL) {
++    // Q
++    if (isBATCHMATMUL4D) {
++      HloInstruction const* Q = custom_call->operand(operand++);
++      int q = Q->literal().Get<int>({});
++      arguments.push_back(b_.getInt32(q));
++    }
++
++    // P
++    HloInstruction const* P = custom_call->operand(operand++);
++    int p = P->literal().Get<int>({});
++    arguments.push_back(b_.getInt32(p));
++  }
++
++  // M
++  HloInstruction const* M = custom_call->operand(operand++);
++  int m = M->literal().Get<int>({});
++  arguments.push_back(b_.getInt32(m));
++
++  // N
++  HloInstruction const* N = custom_call->operand(operand++);
++  int n = N->literal().Get<int>({});
++  arguments.push_back(b_.getInt32(n));
++
++  if (isGEMM || isBATCHMATMUL) {
++    // K
++    HloInstruction const* K = custom_call->operand(operand++);
++    int k = K->literal().Get<int>({});
++    arguments.push_back(b_.getInt32(k));
++  }
++
++  float beta = 0.0;
++  if (isGEMM || isGEMV) {
++    // Alpha
++    HloInstruction const* Alpha = custom_call->operand(operand++);
++    float alpha = Alpha->literal().Get<float>({});
++    llvm::Constant* alphaConst = llvm::ConstantFP::get(b_.getFloatTy(), alpha);
++    arguments.push_back(alphaConst);
++
++    // Beta
++    HloInstruction const* Beta = custom_call->operand(operand++);
++    beta = Beta->literal().Get<float>({});
++    llvm::Constant* betaConst = llvm::ConstantFP::get(b_.getFloatTy(), beta);
++    arguments.push_back(betaConst);
++  }
++
++  // C (or Y in GEMV)
++  HloInstruction const* C = custom_call;
++
++  TF_ASSIGN_OR_RETURN(const BufferAllocation::Slice c_slice,
++                      assignment_.GetUniqueSlice(C, {}));
++  llvm::Value* C_ptr = EmitBufferPointer(c_slice, C->shape());
++  arguments.push_back(C_ptr);
++
++  TF_RETURN_IF_ERROR(EmitTargetAddressForOp(custom_call));
++
++  EmitCallToFunc(metadata.op_name(), arguments, b_.getVoidTy());
++
++  return OkStatus();
++}
++
+ Status IrEmitter::HandleCustomCall(HloInstruction* custom_call) {
+   if (custom_call->custom_call_target() == "PadToStatic") {
+     return HandlePadToStatic(custom_call);
+@@ -2478,9 +2629,15 @@ Status IrEmitter::HandleCustomCall(HloInstruction* custom_call) {
+   if (custom_call->custom_call_target() == "SliceToDynamic") {
+     return HandleSliceToDynamic(custom_call);
+   }
++  if (custom_call->custom_call_target() == "KernelSelector") {
++    return HandleKernelSelector(custom_call);
++  }
+   if (custom_call->custom_call_target() == "TopK") {
+     return HandleTopK(custom_call);
+   }
++  if (custom_call->custom_call_target() == kCustomCallXnnPackSoftMax) {
++    return HandleXnnPackSoftMax(custom_call);
++  }
+ #if defined(INTEL_MKL) && defined(ENABLE_ONEDNN_V3)
+   if (custom_call->custom_call_target() == "__onednn$matmul") {
+     return HandleOneDnnMatMul(custom_call);
diff --git a/install/xla/ir_emitter.h.patch b/install/xla/ir_emitter.h.patch
new file mode 100644
index 0000000..bdf9ebf
--- /dev/null
+++ b/install/xla/ir_emitter.h.patch
@@ -0,0 +1,15 @@
+diff --git a/xla/service/cpu/ir_emitter.h b/xla/service/cpu/ir_emitter.h
+index c4534fa619..1ea0bbaca8 100644
+--- a/xla/service/cpu/ir_emitter.h
++++ b/xla/service/cpu/ir_emitter.h
+@@ -190,8 +190,10 @@ class IrEmitter : public DfsHloVisitorWithDefault,
+   Status HandleSliceToDynamic(HloInstruction* hlo);
+   Status HandlePadToStatic(HloInstruction* hlo);
+   Status HandleTopK(HloInstruction* hlo);
++  Status HandleKernelSelector(HloInstruction* hlo);
+   Status HandleAllReduceSingleReplica(HloInstruction* crs);
+   Status HandleAllReduceMultipleReplica(HloInstruction* crs);
++  Status HandleXnnPackSoftMax(HloInstruction* hlo);
+ #if defined(INTEL_MKL) && defined(ENABLE_ONEDNN_V3)
+   Status HandleOneDnnMatMul(HloInstruction* hlo);
+ #endif  // INTEL_MKL && ENABLE_ONEDNN_V3
diff --git a/install/xla/simple_orc_jit.cc.patch b/install/xla/simple_orc_jit.cc.patch
new file mode 100644
index 0000000..656218c
--- /dev/null
+++ b/install/xla/simple_orc_jit.cc.patch
@@ -0,0 +1,53 @@
+diff --git a/xla/service/cpu/simple_orc_jit.cc b/xla/service/cpu/simple_orc_jit.cc
+index be8741a40f..d1d1bd56e0 100644
+--- a/xla/service/cpu/simple_orc_jit.cc
++++ b/xla/service/cpu/simple_orc_jit.cc
+@@ -38,6 +38,7 @@ limitations under the License.
+ #include "llvm/Support/Process.h"
+ #include "llvm/TargetParser/Host.h"
+ #include "mlir/ExecutionEngine/CRunnerUtils.h"  // from @llvm-project
++#include "tsl/platform/logging.h"
+ #include "xla/service/cpu/cpu_runtime.h"
+ #include "xla/service/cpu/orc_jit_memory_mapper.h"
+ #include "xla/service/cpu/runtime_conv2d.h"
+@@ -58,15 +59,17 @@ limitations under the License.
+ #include "xla/service/cpu/runtime_single_threaded_matmul.h"
+ #include "xla/service/cpu/runtime_topk.h"
+ #include "xla/service/cpu/windows_compatibility.h"
++#include <xnnpack_ops.h>
+ #include "xla/service/custom_call_target_registry.h"
+ #include "xla/types.h"
+ #include "xla/util.h"
+-#include "tsl/platform/logging.h"
+ 
+ #if defined(INTEL_MKL) && defined(ENABLE_ONEDNN_V3)
+ #include "xla/service/cpu/onednn_matmul.h"
+ #endif
+ 
++#include <kernel_selector.h>
++
+ // Provided by compiler-rt and MLIR.
+ // Converts an F32 value to a BF16.
+ extern "C" uint16_t __truncsfbf2(float);
+@@ -514,6 +517,7 @@ bool RegisterKnownJITSymbols() {
+   REGISTER_CPU_RUNTIME_SYMBOL(EigenSingleThreadedMatMulC64);
+   REGISTER_CPU_RUNTIME_SYMBOL(EigenSingleThreadedMatMulC128);
+   REGISTER_CPU_RUNTIME_SYMBOL(EigenSingleThreadedMatMulS32);
++  REGISTER_CPU_RUNTIME_SYMBOL(XnnPackSoftMaxND);
+   REGISTER_CPU_RUNTIME_SYMBOL(ParallelForkJoin);
+   REGISTER_CPU_RUNTIME_SYMBOL(PrintfToStderr);
+   REGISTER_CPU_RUNTIME_SYMBOL(ReleaseInfeedBufferAfterDequeue);
+@@ -526,6 +530,13 @@ bool RegisterKnownJITSymbols() {
+ #if defined(INTEL_MKL) && defined(ENABLE_ONEDNN_V3)
+   REGISTER_CPU_RUNTIME_SYMBOL(OneDnnMatMul);
+ #endif  // INTEL_MKL && ENABLE_ONEDNN_V3
++  REGISTER_CPU_RUNTIME_SYMBOL(KernelSelectorGEMM);
++  REGISTER_CPU_RUNTIME_SYMBOL(KernelSelectorBatch3D);
++  REGISTER_CPU_RUNTIME_SYMBOL(KernelSelectorGEMV);
++  REGISTER_CPU_RUNTIME_SYMBOL(KernelSelectorGEMMMLIR);
++  REGISTER_CPU_RUNTIME_SYMBOL(KernelSelectorBatch3DMLIR);
++  REGISTER_CPU_RUNTIME_SYMBOL(KernelSelectorBatch4DMLIR);
++  REGISTER_CPU_RUNTIME_SYMBOL(KernelSelectorGEMVMLIR);
+ 
+   registry->Register("__gnu_f2h_ieee", reinterpret_cast<void*>(__gnu_f2h_ieee),
+                      "Host");
diff --git a/install/xla/xla.proto.patch b/install/xla/xla.proto.patch
new file mode 100644
index 0000000..244062e
--- /dev/null
+++ b/install/xla/xla.proto.patch
@@ -0,0 +1,15 @@
+diff --git a/xla/xla.proto b/xla/xla.proto
+index 57935c98c0..64998d5f91 100644
+--- a/xla/xla.proto
++++ b/xla/xla.proto
+@@ -546,6 +546,10 @@ message DebugOptions {
+
+   bool xla_cpu_enable_mlir_fusion_outlining = 192;
+
++  bool xla_cpu_enable_xnnpack = 266;
++
++  bool xla_cpu_use_kernel_selector = 267;
++
+   // If set, use the experimental deallocation pass from mlir-hlo.
+   bool xla_cpu_enable_experimental_deallocation = 191;
+
diff --git a/third_party/openblas/openblas.BUILD b/third_party/openblas/openblas.BUILD
index 5b7f8a6..de45b2d 100644
--- a/third_party/openblas/openblas.BUILD
+++ b/third_party/openblas/openblas.BUILD
@@ -4,7 +4,7 @@ genrule(
     outs = ["libopenblas.a"],
     cmd = """
         cd $$(dirname $(location //:README.md)) && \
-        make NO_SHARED=1 ONLY_CBLAS=1 && \
+        make NO_SHARED=1 ONLY_CBLAS=1 TARGET=ARMV8 ARCH=arm64 && \
         cd - && \
         cp $$(dirname $(location //:README.md))/libopenblas_*.a $@
     """,
