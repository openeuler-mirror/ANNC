diff --git a/third_party/tsl/third_party/llvm/annc4.patch b/third_party/tsl/third_party/llvm/annc4.patch
new file mode 100644
index 0000000..0ab9516
--- /dev/null
+++ b/third_party/tsl/third_party/llvm/annc4.patch
@@ -0,0 +1,554 @@
+diff --git a/mlir/include/mlir/Dialect/Bufferization/IR/BufferizationOps.td b/mlir/include/mlir/Dialect/Bufferization/IR/BufferizationOps.td
+index 34a6f5d74b13..c3c6be05a301 100644
+--- a/mlir/include/mlir/Dialect/Bufferization/IR/BufferizationOps.td
++++ b/mlir/include/mlir/Dialect/Bufferization/IR/BufferizationOps.td
+@@ -529,6 +529,17 @@ def Bufferization_ToMemrefOp : Bufferization_Op<"to_memref", [
+       return true;
+     }
+ 
++    bool mustBufferizeInPlace(OpOperand &opOperand,
++                              const AnalysisState &state) {
++      // ToMemrefOps always bufferize inplace.
++      //
++      // This was removed upstream in this commit:
++      // https://github.com/llvm/llvm-project/commit/4ef60283403f8277ff1048de5905af99fd2ed81d
++      // which means that this is probably a huge hack.
++      // TODO: Properly investigate this!
++      return true;
++    }
++
+     bool bufferizesToMemoryWrite(OpOperand &opOperand,
+                                  const AnalysisState &state) {
+       return !getReadOnly();
+diff --git a/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.h b/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.h
+index d2dd95416241..e9da68c44a22 100644
+--- a/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.h
++++ b/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.h
+@@ -27,6 +27,9 @@ std::unique_ptr<Pass> createTensorBufferizePass();
+ /// Creates an instance of the concat decomposition pass.
+ std::unique_ptr<Pass> createDecomposeTensorConcatPass();
+ 
++/// Creates an instance of the concat removal pass.
++std::unique_ptr<Pass> createConcatRemovalPass();
++
+ //===----------------------------------------------------------------------===//
+ // Registration
+ //===----------------------------------------------------------------------===//
+diff --git a/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.td b/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.td
+index d30e5fcb604d..c88515fb015c 100644
+--- a/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.td
++++ b/mlir/include/mlir/Dialect/Tensor/Transforms/Passes.td
+@@ -43,4 +43,31 @@ def DecomposeTensorConcat : Pass<"decompose-tensor-concat"> {
+   let dependentDialects = ["tensor::TensorDialect"];
+ }
+ 
++def ConcatRemoval : Pass<"concat-removal"> {
++  let summary = "Remove concat by rewriting ops to write directly into the output buffer";
++  let description = [{
++    Rewrite ops which results are concatenated to write instead directly
++    into a big tensor shared by all ops, thus removing the necessity of
++    concatenating the partial output of the ops. e.g., rewrite:
++
++    %0 = tensor.empty() : tensor<8xf32>
++    %1 = linalg.elemwise(%0: tensor<8xf32>) outs(%0: tensor<8xf32>)
++    %2 = tensor.empty() : tensor<8xf32>
++    %3 = linalg.elemwise(%2: tensor<8xf32>) outs(%2: tensor<8xf32>)
++    %concat = tensor.concat dim(0) %1, %3 : (tensor<8xf32>, tensor<8xf32>) -> tensor<16xf32>
++
++    into:
++
++    %0 = tensor.empty() : tensor<16xf32>
++    %1 = extract_slice %0 : tensor<16xf32> -> tensor<8xf32>
++    %2 = linalg.elemwise(%1: tensor<8xf32>) outs(%1: tensor<8xf32>)
++    %3 = insert_slice %2 into %0
++    %4 = extract_slice %3 : tensor<16xf32> -> tensor<8xf32>
++    %5 = linalg.elemwise(%4: tensor<8xf32>) outs(%4: tensor<8xf32>)
++    %6 = insert_slice %5 into %4
++  }];
++  let constructor = "mlir::tensor::createConcatRemovalPass()";
++  let dependentDialects = ["tensor::TensorDialect"];
++}
++
+ #endif // MLIR_DIALECT_TENSOR_TRANSFORMS_PASSES
+diff --git a/mlir/include/mlir/Dialect/Tensor/Transforms/Transforms.h b/mlir/include/mlir/Dialect/Tensor/Transforms/Transforms.h
+index 44b8377bd6aa..4cad1aaa212f 100644
+--- a/mlir/include/mlir/Dialect/Tensor/Transforms/Transforms.h
++++ b/mlir/include/mlir/Dialect/Tensor/Transforms/Transforms.h
+@@ -74,6 +74,12 @@ void populateFoldTensorEmptyPatterns(RewritePatternSet &patterns,
+ /// that it can be bufferized into a sequence of copies.
+ void populateDecomposeTensorConcatPatterns(RewritePatternSet &patterns);
+ 
++/// Populates `patterns` with patterns that rewrite ops which results
++/// are concatenated to write instead directly into a big tensor shared
++/// by all ops, thus removing the necessity of concatenating the partial
++/// output of the ops.
++void populateConcatRemovalPatterns(RewritePatternSet &patterns);
++
+ /// Populates `patterns` with patterns that fold operations like `tensor.pad`
+ /// and `tensor.extract_slice` into `tensor.pack` and `tensor.unpack` operations
+ /// respectively.
+diff --git a/mlir/lib/Dialect/Bufferization/Transforms/OneShotAnalysis.cpp b/mlir/lib/Dialect/Bufferization/Transforms/OneShotAnalysis.cpp
+index f590e3d9da8e..dc625fbbe67b 100644
+--- a/mlir/lib/Dialect/Bufferization/Transforms/OneShotAnalysis.cpp
++++ b/mlir/lib/Dialect/Bufferization/Transforms/OneShotAnalysis.cpp
+@@ -223,6 +223,12 @@ bool OneShotAnalysisState::isValueWritten(Value value) const {
+ }
+ 
+ bool OneShotAnalysisState::isWritable(Value value) const {
++  // THIS IS A HUGE HACK AND WE SHOULD FIND A BETTER WAY TO DO THIS!
++  if (dyn_cast<ToTensorOp>(getOwnerOfValue(value))) {
++    llvm::errs() << "WARNING: Assuming ToTensorOp is writable\n";
++    return true;
++  }
++
+   // TODO: Out-of-place bufferized value could be considered writable.
+   // Query BufferizableOpInterface to see if the BlockArgument is writable.
+   if (auto bufferizableOp =
+@@ -1189,7 +1195,8 @@ checkPreBufferizationAssumptions(Operation *op, const DominanceInfo &domInfo,
+     }
+ 
+     for (OpOperand &opOperand : op->getOpOperands()) {
+-      if (isa<TensorType>(opOperand.get().getType())) {
++      // ToMemrefOp does not write into the buffer ?
++      if (isa<TensorType>(opOperand.get().getType()) && !dyn_cast<ToMemrefOp>(op.getOperation())) {
+         if (wouldCreateReadAfterWriteInterference(
+                 opOperand, domInfo, state,
+                 /*checkConsistencyOnly=*/true)) {
+diff --git a/mlir/lib/Dialect/Tensor/Transforms/ConcatOpPatterns.cpp b/mlir/lib/Dialect/Tensor/Transforms/ConcatOpPatterns.cpp
+index a9b08fce84e1..edeac4280e7d 100644
+--- a/mlir/lib/Dialect/Tensor/Transforms/ConcatOpPatterns.cpp
++++ b/mlir/lib/Dialect/Tensor/Transforms/ConcatOpPatterns.cpp
+@@ -10,6 +10,7 @@
+ #include "mlir/Dialect/Arith/IR/Arith.h"
+ #include "mlir/Dialect/Arith/Utils/Utils.h"
+ #include "mlir/Dialect/Tensor/IR/Tensor.h"
++#include "mlir/Dialect/Func/IR/FuncOps.h"
+ #include "mlir/Dialect/Tensor/Transforms/Passes.h"
+ #include "mlir/Dialect/Tensor/Transforms/Transforms.h"
+ #include "mlir/IR/PatternMatch.h"
+@@ -18,6 +19,7 @@
+ namespace mlir {
+ namespace tensor {
+ #define GEN_PASS_DEF_DECOMPOSETENSORCONCAT
++#define GEN_PASS_DEF_CONCATREMOVAL
+ #include "mlir/Dialect/Tensor/Transforms/Passes.h.inc"
+ } // namespace tensor
+ } // namespace mlir
+@@ -94,6 +96,193 @@ struct DecomposeTensorConcatOp : public OpRewritePattern<ConcatOp> {
+   }
+ };
+ 
++struct ConcatRemoval : public OpRewritePattern<ConcatOp> {
++  using OpRewritePattern<ConcatOp>::OpRewritePattern;
++ 
++  // TODO: This is very verbose. This is important in the initial stages but once this
++  // transformation is mature we should probably use VLOG for this.
++  static FailureOr<std::pair<Operation*, RankedTensorType>>
++  isOperandErasable(Value input) {
++    Operation* op = input.getDefiningOp();
++    if (!op) {
++      llvm::errs() << "[concat-removal] concat input is not coming from an operation\n";
++      return failure();
++    }
++ 
++    auto dpsOp = dyn_cast<DestinationStyleOpInterface>(op);
++    if (!dpsOp) {
++      llvm::errs() << "[concat-removal] concat input is not DPS\n";
++      return failure();
++    }
++ 
++    if (dpsOp.getNumDpsInits() != 1) {
++      llvm::errs() << "[concat-removal] concat input DPS does not have 1 init argument\n";
++      return failure();
++    }
++ 
++    auto emptyTensorOp = dyn_cast<tensor::EmptyOp>(dpsOp.getDpsInits()[0].getDefiningOp());
++    if (!emptyTensorOp) {
++      llvm::errs() << "[concat-removal] concat input does not write into an empty op\n";
++      return failure();
++    }
++ 
++    RankedTensorType type = dyn_cast<RankedTensorType>(emptyTensorOp.getType());
++    if (!type) {
++      llvm::errs() << "[concat-removal] concat input writes into an unranked empty op\n";
++      return failure();
++    }
++ 
++    return std::make_pair(op, type);
++  }
++
++  /// Given a `concatOp` as input, it fills in `erasableOperands` and `tensorShapes` vectors,
++  /// representing the list of erasableOperands and the result type of each operation, respectively.
++  ///
++  /// A concat operand is considered erasable if both:
++  /// 1. isOperandErasable returns true
++  /// 2. It is consecutive (in the operand list) with another erasable operand.
++  ///
++  /// When a "gap" is detected (i.e., an erasable operand is followed by an unerasable operand),
++  /// the function returns. In other words, it only captures the first sequence of consecutive
++  /// erasable operands in `concatOp`.
++  static void
++  getOperandsToErase(SmallVector<Value> inputs, SmallVector<Operation*> &erasableOperands, SmallVector<bool> & erasable) {    
++    for (auto [idx, input] : llvm::enumerate(inputs)) {
++      FailureOr<std::pair<Operation*, RankedTensorType>> maybeOp = isOperandErasable(input);
++      if (!failed(maybeOp)) {
++        // The input is erasable, add it to the list.   
++        erasableOperands.push_back((*maybeOp).first);        
++        erasable.push_back(true);
++      } else {    
++        erasableOperands.push_back(nullptr);        
++        erasable.push_back(false);
++      }
++    }        
++  }
++
++  static int64_t
++  computeConcatOffset(ConcatOp concatOp, Value operand) {
++    auto operands = concatOp.getInputs();
++
++    // 1. Get the index of the operand within the concat op.
++    int32_t idx = -1;
++    for (auto [i, input] : llvm::enumerate(operands)) {
++      if (operand == input) {
++        idx = i;
++        break;
++      }
++    }
++    assert(idx >= 0);
++
++    // 2. Get the offset by accumulating all offsets before the operand.
++    int64_t off = 0;
++    for (int i = 0; i < idx; i++) {
++      off += cast<RankedTensorType>(operands[i].getType()).getShape()[concatOp.getDim()];
++    }
++    return off;
++  }
++ 
++  LogicalResult matchAndRewrite(ConcatOp concatOp,
++                                PatternRewriter &rewriter) const override {
++    Location loc = concatOp.getLoc();
++    // This should never happen by construction
++    assert(concatOp->getNumResults() == 1);
++    assert(concatOp->getResultTypes().size() == 1);
++
++    // TODO: Discard dynamic tensor inputs.
++ 
++    // The concat result is used by more than one op; this case is not supported, skip.
++    if (llvm::to_vector(concatOp->getResult(0).getUsers()).size() != 1) {
++      llvm::errs() << "[concat-removal] concat result has more than one use\n";
++      return failure();
++    }
++
++    SmallVector<Value> sortedInputs = concatOp.getInputs();
++    std::sort(sortedInputs.begin(), sortedInputs.end(), [&](Value v1, Value v2) {
++        Operation *op1 = v1.getDefiningOp();
++        Operation *op2 = v2.getDefiningOp();
++        if (!op1) return true;
++        if (!op2) return false;
++
++        return op1->isBeforeInBlock(op2);
++      }
++    );
++
++    for (auto sss : sortedInputs) {
++      llvm::errs() << "--> ";
++      sss.dump();
++    }
++ 
++    // Get all operands to be erased.
++    SmallVector<Operation*> erasableOperands;    
++    SmallVector<bool> erasable;
++    getOperandsToErase(sortedInputs, erasableOperands, erasable);
++    assert(erasableOperands.size() == erasable.size());
++ 
++    // Compute the size of the new tensor
++    int64_t dim = concatOp.getDim();
++    RankedTensorType concatResultTy = cast<RankedTensorType>(concatOp.getResultType());
++    std::vector<int64_t> newShape = concatResultTy.getShape();
++ 
++    // IR rewriting starts now, begining with the new tensor creation.
++    rewriter.setInsertionPointToStart(concatOp->getBlock());
++    auto emptyTensor = rewriter.create<tensor::EmptyOp>(loc, newShape, concatResultTy.getElementType());
++ 
++    // Replace the inits of every operation with an extract_slice of the new tensor and insert the
++    // output of every operation back to the big tensor (insert_slice)
++    SmallVector<Value> lastResult;
++    lastResult.push_back(emptyTensor);       
++ 
++    for (auto [idx, operand] : llvm::enumerate(sortedInputs)) {
++      
++      auto shape = cast<RankedTensorType>(operand.getType()).getShape();
++
++      SmallVector<OpFoldResult> offsets;
++      for (int i = 0; i < cast<RankedTensorType>(operand.getType()).getRank(); i++) {
++        if (i == dim) {
++          offsets.push_back(rewriter.getIndexAttr(computeConcatOffset(concatOp, operand)));
++        }
++        else
++          offsets.push_back(rewriter.getIndexAttr(0));
++      }
++      SmallVector<OpFoldResult> sizes;
++      for (auto s : shape)
++        sizes.push_back(rewriter.getIndexAttr(s));
++      SmallVector<OpFoldResult> strides(offsets.size(), rewriter.getIndexAttr(1));
++
++      if (erasable[idx]) {
++        Operation* op = erasableOperands[idx];
++        // 1. Create the extract_slice.
++        // rewriter.setInsertionPoint(op);
++        auto extractSliceOp = rewriter.create<tensor::ExtractSliceOp>(loc, lastResult.back(), offsets, sizes, strides);
++  
++        // 2. Use the extract_slice as the output operand of the op.
++        auto dpsOp = cast<DestinationStyleOpInterface>(op);
++        dpsOp.getDpsInitsMutable()[0].set(extractSliceOp);      
++  
++        // 3. Create the insert_slice.      
++        rewriter.setInsertionPointAfter(op);
++        auto insertSliceOp = rewriter.create<tensor::InsertSliceOp>(loc, dpsOp->getResult(0), lastResult.back(), offsets, sizes, strides);
++        lastResult.push_back(insertSliceOp);
++      }
++      else {
++        // 3. Create the insert_slice.      
++        // lastResult contains either tensor.empty or tensor.insert_slice so we can use getDefiningOp safely.
++        if (operand.getDefiningOp())
++          rewriter.setInsertionPointAfter(operand.getDefiningOp());
++        else
++          rewriter.setInsertionPointAfter(lastResult.back().getDefiningOp());
++        auto insertSliceOp = rewriter.create<tensor::InsertSliceOp>(loc, operand, lastResult.back(), offsets, sizes, strides);
++        lastResult.push_back(insertSliceOp);
++      }
++    }
++
++
++    rewriter.replaceOp(concatOp, lastResult.back());
++    return success();
++  }
++};
++
+ } // namespace
+ 
+ void mlir::tensor::populateDecomposeTensorConcatPatterns(
+@@ -101,6 +290,11 @@ void mlir::tensor::populateDecomposeTensorConcatPatterns(
+   patterns.add<DecomposeTensorConcatOp>(patterns.getContext());
+ }
+ 
++void mlir::tensor::populateConcatRemovalPatterns(
++    RewritePatternSet &patterns) {
++  patterns.add<ConcatRemoval>(patterns.getContext());
++}
++
+ //===----------------------------------------------------------------------===//
+ // Pass registration
+ //===----------------------------------------------------------------------===//
+@@ -113,6 +307,12 @@ struct DecomposeTensorConcatPass final
+   void runOnOperation() override;
+ };
+ 
++struct ConcatRemovalPass final
++    : public tensor::impl::ConcatRemovalBase<
++          ConcatRemovalPass> {
++  void runOnOperation() override;
++};
++
+ } // namespace
+ 
+ void DecomposeTensorConcatPass::runOnOperation() {
+@@ -121,6 +321,16 @@ void DecomposeTensorConcatPass::runOnOperation() {
+   (void)applyPatternsAndFoldGreedily(getOperation(), std::move(patterns));
+ }
+ 
++void ConcatRemovalPass::runOnOperation() {
++  RewritePatternSet patterns(&getContext());
++  tensor::populateConcatRemovalPatterns(patterns);
++  (void)applyPatternsAndFoldGreedily(getOperation(), std::move(patterns));
++}
++
+ std::unique_ptr<Pass> tensor::createDecomposeTensorConcatPass() {
+   return std::make_unique<DecomposeTensorConcatPass>();
++}
++
++std::unique_ptr<Pass> tensor::createConcatRemovalPass() {
++  return std::make_unique<ConcatRemovalPass>();
+ }
+\ No newline at end of file
+diff --git a/mlir/test/Dialect/Tensor/concat-removal.mlir b/mlir/test/Dialect/Tensor/concat-removal.mlir
+new file mode 100644
+index 000000000000..25c082578fcd
+--- /dev/null
++++ b/mlir/test/Dialect/Tensor/concat-removal.mlir
+@@ -0,0 +1,174 @@
++// RUN: mlir-opt --concat-removal -split-input-file --verify-diagnostics %s | FileCheck %s
++
++// /home/pablo/boss-project/my_xla_build_downstream/e26518957b104c0bdc4afb0e2d30f520/execroot/xla/bazel-out/aarch64-opt/bin/xla//mlir_hlo/mlir-hlo-opt xla-dev-llvm/mlir/test/Dialect/Tensor/concat-removal.mlir  --concat-removal --split-input-file --verify-diagnostics  | /home/pablo/iree-llvm-sandbox/build/bin/FileCheck xla-dev-llvm/mlir/test/Dialect/Tensor/concat-removal.mlir
++
++// CHECK-LABEL: func @remove_concat(  
++//       CHECK:   tensor.empty() : tensor<256x64xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat(%arg0: tensor<256x16xi1>, %arg1: tensor<256x16xf32>, %arg2: tensor<256x16xf32>, %arg3: tensor<256x16xf32>, %arg4: tensor<256x16xf32>) -> tensor<256x64xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++  
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg1 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x16xf32>
++  %mapped_0 = linalg.map { arith.select } ins(%arg0, %cst, %arg2 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%1 : tensor<256x16xf32>)
++  %2 = tensor.empty() : tensor<256x16xf32>
++  %mapped_1 = linalg.map { arith.select } ins(%arg0, %cst, %arg3 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%2 : tensor<256x16xf32>)
++  %3 = tensor.empty() : tensor<256x16xf32>
++  %mapped_2 = linalg.map { arith.select } ins(%arg0, %cst, %arg4 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%3 : tensor<256x16xf32>)
++
++  %concat = tensor.concat dim(1) %mapped, %mapped_0, %mapped_1, %mapped_2 : (tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>) -> tensor<256x64xf32>
++  return %concat : tensor<256x64xf32>
++}
++
++// -----
++
++// CHECK-LABEL: func @remove_concat_partially(
++//       CHECK:   tensor.empty() : tensor<256x64xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat_partially(%arg0: tensor<256x16xi1>, %arg1: tensor<256x16xf32>, %arg2: tensor<256x16xf32>, %arg3: tensor<256x16xf32>, %arg4: tensor<256x16xf32>) -> tensor<256x64xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg1 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x16xf32>
++  %mapped_0 = linalg.map { arith.select } ins(%arg0, %cst, %arg2 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%1 : tensor<256x16xf32>)
++
++  %concat = tensor.concat dim(1) %mapped, %mapped_0, %arg3, %arg4 : (tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>) -> tensor<256x64xf32>
++  return %concat : tensor<256x64xf32>
++}
++
++// -----
++
++// CHECK-LABEL: func @remove_concat_gaps(
++//       CHECK:   tensor.empty() : tensor<256x64xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat_gaps(%arg0: tensor<256x16xi1>, %arg1: tensor<256x16xf32>, %arg2: tensor<256x16xf32>, %arg3: tensor<256x16xf32>, %arg4: tensor<256x16xf32>) -> tensor<256x64xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg1 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x16xf32>
++  %mapped_0 = linalg.map { arith.select } ins(%arg0, %cst, %arg2 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%1 : tensor<256x16xf32>)
++  %2 = tensor.empty() : tensor<256x16xf32>
++  %mapped_1 = linalg.map { arith.select } ins(%arg0, %cst, %arg4 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%2 : tensor<256x16xf32>)
++
++  %concat = tensor.concat dim(1) %mapped, %mapped_0, %arg3, %mapped_1 : (tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>) -> tensor<256x64xf32>  
++  return %concat : tensor<256x64xf32>
++}
++
++// -----
++
++// CHECK-LABEL: func @remove_concat_several_gaps(
++//       CHECK:   tensor.empty() : tensor<256x160xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat_several_gaps(%arg0: tensor<256x16xi1>, %arg1: tensor<256x16xf32>, %arg2: tensor<256x16xf32>, %arg3: tensor<256x16xf32>, %arg4: tensor<256x16xf32>, %arg5: tensor<256x16xf32>, %arg6: tensor<256x16xf32>, %arg7: tensor<256x16xf32>) -> tensor<256x160xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg1 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x16xf32>
++  %mapped_0 = linalg.map { arith.select } ins(%arg0, %cst, %arg2 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%1 : tensor<256x16xf32>)
++  %2 = tensor.empty() : tensor<256x16xf32>
++  %mapped_1 = linalg.map { arith.select } ins(%arg0, %cst, %arg3 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%2 : tensor<256x16xf32>)
++  %3 = tensor.empty() : tensor<256x16xf32>
++  %mapped_2 = linalg.map { arith.select } ins(%arg0, %cst, %arg4 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%3 : tensor<256x16xf32>)
++  %4 = tensor.empty() : tensor<256x16xf32>
++  %mapped_3 = linalg.map { arith.select } ins(%arg0, %cst, %arg5 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%4 : tensor<256x16xf32>)
++  %5 = tensor.empty() : tensor<256x16xf32>
++  %mapped_4 = linalg.map { arith.select } ins(%arg0, %cst, %arg6 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%5 : tensor<256x16xf32>)
++  %6 = tensor.empty() : tensor<256x16xf32>
++  %mapped_5 = linalg.map { arith.select } ins(%arg0, %cst, %arg7 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%6 : tensor<256x16xf32>)
++
++  %concat = tensor.concat dim(1) %mapped, %mapped_0, %arg1, %mapped_1, %mapped_2, %arg2, %mapped_3, %mapped_4, %mapped_5, %arg3  : (tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>) -> tensor<256x160xf32>
++  return %concat : tensor<256x160xf32>
++}
++
++// -----
++
++// CHECK-LABEL: func @remove_concat_several_gaps2(
++//       CHECK:   tensor.empty() : tensor<256x128xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat_several_gaps2(%arg0: tensor<256x16xi1>, %arg1: tensor<256x16xf32>, %arg2: tensor<256x16xf32>, %arg3: tensor<256x16xf32>, %arg4: tensor<256x16xf32>, %arg5: tensor<256x16xf32>, %arg6: tensor<256x16xf32>, %arg7: tensor<256x16xf32>) -> tensor<256x128xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg1 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x16xf32>
++  %mapped_0 = linalg.map { arith.select } ins(%arg0, %cst, %arg2 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%1 : tensor<256x16xf32>)
++  %2 = tensor.empty() : tensor<256x16xf32>
++  %mapped_1 = linalg.map { arith.select } ins(%arg0, %cst, %arg3 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%2 : tensor<256x16xf32>)
++  %3 = tensor.empty() : tensor<256x16xf32>
++  %mapped_2 = linalg.map { arith.select } ins(%arg0, %cst, %arg4 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%3 : tensor<256x16xf32>)
++  %4 = tensor.empty() : tensor<256x16xf32>
++  %mapped_3 = linalg.map { arith.select } ins(%arg0, %cst, %arg5 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%4 : tensor<256x16xf32>)
++  %5 = tensor.empty() : tensor<256x16xf32>
++  %mapped_4 = linalg.map { arith.select } ins(%arg0, %cst, %arg6 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%5 : tensor<256x16xf32>)
++  %6 = tensor.empty() : tensor<256x16xf32>
++  %mapped_5 = linalg.map { arith.select } ins(%arg0, %cst, %arg7 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%6 : tensor<256x16xf32>)
++
++  %concat = tensor.concat dim(1) %mapped, %arg1, %mapped_1, %arg2, %mapped_2, %mapped_3, %mapped_4, %mapped_5 : (tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>) -> tensor<256x128xf32>
++  return %concat : tensor<256x128xf32>
++}
++
++// -----
++
++// CHECK-LABEL: func @remove_concat_different_shapes(
++//       CHECK:   tensor.empty() : tensor<256x180xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat_different_shapes(%arg0: tensor<256x16xi1>, %arg1: tensor<256x32xi1>, %arg2: tensor<256x4xi1>, %arg3: tensor<256x128xi1>, %arg4: tensor<256x16xf32>, %arg5: tensor<256x32xf32>, %arg6: tensor<256x4xf32>, %arg7: tensor<256x128xf32>) -> tensor<256x180xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++  %cst_0 = arith.constant dense<0.000000e+00> : tensor<256x32xf32>
++  %cst_1 = arith.constant dense<0.000000e+00> : tensor<256x4xf32>
++  %cst_2 = arith.constant dense<0.000000e+00> : tensor<256x128xf32>
++
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg4 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x32xf32>
++  %mapped_3 = linalg.map { arith.select } ins(%arg1, %cst_0, %arg5 : tensor<256x32xi1>, tensor<256x32xf32>, tensor<256x32xf32>) outs(%1 : tensor<256x32xf32>)
++  %2 = tensor.empty() : tensor<256x4xf32>
++  %mapped_4 = linalg.map { arith.select } ins(%arg2, %cst_1, %arg6 : tensor<256x4xi1>, tensor<256x4xf32>, tensor<256x4xf32>) outs(%2 : tensor<256x4xf32>)
++  %3 = tensor.empty() : tensor<256x128xf32>
++  %mapped_5 = linalg.map { arith.select } ins(%arg3, %cst_2, %arg7 : tensor<256x128xi1>, tensor<256x128xf32>, tensor<256x128xf32>) outs(%3 : tensor<256x128xf32>)
++
++  %concat = tensor.concat dim(1) %mapped, %mapped_3, %mapped_4, %mapped_5 : (tensor<256x16xf32>, tensor<256x32xf32>, tensor<256x4xf32>, tensor<256x128xf32>) -> tensor<256x180xf32>
++  return %concat : tensor<256x180xf32>
++}
++
++// -----
++
++// CHECK-LABEL: func @remove_concat_reordered(
++//       CHECK:   tensor.empty() : tensor<256x64xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat_reordered(%arg0: tensor<256x16xi1>, %arg1: tensor<256x16xf32>, %arg2: tensor<256x16xf32>, %arg3: tensor<256x16xf32>, %arg4: tensor<256x16xf32>) -> tensor<256x64xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg1 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x16xf32>
++  %mapped_0 = linalg.map { arith.select } ins(%arg0, %cst, %arg2 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%1 : tensor<256x16xf32>)
++  %2 = tensor.empty() : tensor<256x16xf32>
++  %mapped_1 = linalg.map { arith.select } ins(%arg0, %cst, %arg3 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%2 : tensor<256x16xf32>)
++  %3 = tensor.empty() : tensor<256x16xf32>
++  %mapped_2 = linalg.map { arith.select } ins(%arg0, %cst, %arg4 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%3 : tensor<256x16xf32>)
++
++  %concat = tensor.concat dim(1) %mapped_0, %mapped_1, %mapped, %mapped_2 : (tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>) -> tensor<256x64xf32>
++  return %concat : tensor<256x64xf32>
++}
++
++// -----
++
++// CHECK-LABEL: func @remove_concat_not_possible(
++//       CHECK:   tensor.empty() : tensor<256x64xf32>
++//   CHECK-NOT:   tensor.concat
++func.func @remove_concat_not_possible(%arg0: tensor<256x16xi1>, %arg1: tensor<256x16xf32>, %arg2: tensor<256x16xf32>, %arg3: tensor<256x16xf32>, %arg4: tensor<256x16xf32>) -> tensor<256x64xf32> {
++  %cst = arith.constant dense<0.000000e+00> : tensor<256x16xf32>
++
++  %0 = tensor.empty() : tensor<256x16xf32>
++  %mapped = linalg.map { arith.select } ins(%arg0, %cst, %arg1 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%0 : tensor<256x16xf32>)
++  %1 = tensor.empty() : tensor<256x16xf32>
++  %mapped_0 = linalg.map { arith.select } ins(%arg0, %cst, %arg2 : tensor<256x16xi1>, tensor<256x16xf32>, tensor<256x16xf32>) outs(%1 : tensor<256x16xf32>)
++
++  %concat = tensor.concat dim(1) %mapped, %arg3, %mapped_0, %arg4 : (tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>, tensor<256x16xf32>) -> tensor<256x64xf32>
++  return %concat : tensor<256x64xf32>
++}
+\ No newline at end of file
