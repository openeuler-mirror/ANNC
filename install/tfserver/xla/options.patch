diff --git a/xla/debug_options_flags.cc b/xla/debug_options_flags.cc
index 6063f173a5..d070de671d 100644
--- a/xla/debug_options_flags.cc
+++ b/xla/debug_options_flags.cc
@@ -93,9 +93,8 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {
   // flag.
   opts.set_xla_gpu_enable_cublaslt(false);
 
-  // TODO(b/258036887): Create separate flags for enabling cuBLAS, cuDNN, and
-  // NCCL in GPU graphs.
-  opts.set_xla_gpu_graph_level(1);
+  // TODO(b/258036887): Enable gpu_graph_level=3.
+  opts.set_xla_gpu_graph_level(2);
   opts.set_xla_gpu_graph_num_runs_to_instantiate(-1);
   opts.set_xla_gpu_enable_persistent_temp_buffers(false);
   opts.set_xla_gpu_graph_min_graph_size(5);
@@ -113,8 +112,8 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {
   opts.set_xla_gpu_all_reduce_combine_threshold_bytes(kDefaultThreshold);
   opts.set_xla_gpu_all_gather_combine_threshold_bytes(kDefaultThreshold);
   opts.set_xla_gpu_reduce_scatter_combine_threshold_bytes(kDefaultThreshold);
+
   opts.set_xla_gpu_enable_all_gather_combine_by_dim(true);
-  opts.set_xla_gpu_enable_reduce_scatter_combine_by_dim(true);
 
   opts.set_xla_gpu_enable_async_collectives(false);
   opts.set_xla_gpu_enable_async_all_reduce(true);
@@ -162,6 +161,10 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {
       std::numeric_limits<int64_t>::max());
 
   opts.set_xla_cpu_enable_mlir_tiling_and_fusion(true);
+  opts.set_xla_cpu_enable_concat_optimization(false);
+  opts.set_xla_cpu_enable_concat_removal(false);
+  opts.set_xla_cpu_enable_concat_canonicalization(false);
+  opts.set_xla_cpu_use_matmul_library(false);
   opts.set_xla_cpu_enable_custom_matmul_tiling(false);
   opts.set_xla_cpu_matmul_tiling_m_dim(8);
   opts.set_xla_cpu_matmul_tiling_n_dim(8);
@@ -202,7 +205,6 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {
   opts.set_xla_gpu_enable_while_loop_double_buffering(false);
   opts.set_xla_gpu_ensure_minor_dot_contraction_dims(false);
   opts.set_xla_gpu_filter_kernels_spilling_registers_on_autotuning(true);
-  opts.set_xla_gpu_llvm_verification_level(0);
 
   return opts;
 }
@@ -870,13 +872,6 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,
       debug_options->xla_gpu_enable_all_gather_combine_by_dim(),
       "Combine all-gather ops with the same gather dimension or irrespective "
       "of their dimension."));
-  flag_list->push_back(tsl::Flag(
-      "xla_gpu_enable_reduce_scatter_combine_by_dim",
-      bool_setter_for(
-          &DebugOptions::set_xla_gpu_enable_reduce_scatter_combine_by_dim),
-      debug_options->xla_gpu_enable_reduce_scatter_combine_by_dim(),
-      "Combine reduce-scatter ops with the same dimension or irrespective of "
-      "their dimension."));
   flag_list->push_back(tsl::Flag(
       "xla_gpu_all_reduce_contiguous",
       bool_setter_for(&DebugOptions::set_xla_gpu_all_reduce_contiguous),
@@ -1076,6 +1071,33 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,
       bool_setter_for(&DebugOptions::set_xla_cpu_enable_mlir_tiling_and_fusion),
       debug_options->xla_cpu_enable_mlir_tiling_and_fusion(),
       "Enable MLIR tiling and fusion."));
+  flag_list->push_back(tsl::Flag(
+      "xla_cpu_enable_concat_optimization",
+      bool_setter_for(&DebugOptions::set_xla_cpu_enable_concat_optimization),
+      debug_options->xla_cpu_enable_concat_optimization(),
+      "Enable concat optimization."));
+  flag_list->push_back(tsl::Flag(
+      "xla_cpu_enable_concat_removal",
+      bool_setter_for(&DebugOptions::set_xla_cpu_enable_concat_removal),
+      debug_options->xla_cpu_enable_concat_removal(),
+      "Enable concat removal."));
+  flag_list->push_back(tsl::Flag(
+      "xla_cpu_enable_concat_canonicalization",
+      bool_setter_for(&DebugOptions::set_xla_cpu_enable_concat_canonicalization),
+      debug_options->xla_cpu_enable_concat_canonicalization(),
+      "Enable concat canonicalization."));
+  flag_list->push_back(tsl::Flag(
+      "xla_cpu_use_matmul_library",
+      bool_setter_for(&DebugOptions::set_xla_cpu_use_matmul_library),
+      debug_options->xla_cpu_use_matmul_library(),
+      "Replace mhlo.dot and mhlo.dot_general with library calls to "
+      "an external library."));
+  flag_list->push_back(tsl::Flag(
+      "xla_cpu_enable_output_tensor_reuse",
+      bool_setter_for(&DebugOptions::set_xla_cpu_enable_output_tensor_reuse),
+      debug_options->xla_cpu_enable_output_tensor_reuse(),
+      "Replace the output tensor of gml.st_fusion ops with the "
+      "input tensor when shape matches and it is legal to do so."));
   flag_list->push_back(tsl::Flag(
       "xla_cpu_enable_mlir_fusion_outlining",
       bool_setter_for(&DebugOptions::set_xla_cpu_enable_mlir_fusion_outlining),
@@ -1334,12 +1356,6 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,
       int64_setter_for(&DebugOptions::set_xla_debug_buffer_assignment_show_max),
       debug_options->xla_debug_buffer_assignment_show_max(),
       "Number of buffers to display when debugging the buffer assignment"));
-  flag_list->push_back(tsl::Flag(
-      "xla_gpu_llvm_verification_level",
-      int32_setter_for(&DebugOptions::set_xla_gpu_llvm_verification_level),
-      debug_options->xla_gpu_llvm_verification_level(),
-      "Sets how often we verify the generated llvm modules. Higher "
-      "levels mean more frequent verification. Currently supported: 0, 1."));
 }  // NOLINT(readability/fn_size)
 
 // Allocates flag_values and flag_objects; this function must not be called more
diff --git a/xla/xla.proto b/xla/xla.proto
index 739960065d..f3beb775aa 100644
--- a/xla/xla.proto
+++ b/xla/xla.proto
@@ -384,10 +384,9 @@ message DebugOptions {
   int64 xla_gpu_all_gather_combine_threshold_bytes = 212;
   int64 xla_gpu_reduce_scatter_combine_threshold_bytes = 213;
 
-  // Combine all-gather/scatter-reduce ops with the same dimension or
-  // irrespective of their dimension.
+  // Combine all-gather ops with the same dimension or irrespective of their
+  // dimension.
   bool xla_gpu_enable_all_gather_combine_by_dim = 254;
-  bool xla_gpu_enable_reduce_scatter_combine_by_dim = 257;
 
   // Combine GPU all-reduces into a single operation over a contiguous buffer.
   bool xla_gpu_all_reduce_contiguous = 158;
@@ -532,6 +531,11 @@ message DebugOptions {
   // is enabled, the pipeline will use tiling, fusion, peeling, vectorization
   // instead.
   bool xla_cpu_enable_mlir_tiling_and_fusion = 184;
+  bool xla_cpu_enable_concat_optimization = 256;
+  bool xla_cpu_use_matmul_library = 257;
+  bool xla_cpu_enable_output_tensor_reuse = 258;
+  bool xla_cpu_enable_concat_removal = 259;
+  bool xla_cpu_enable_concat_canonicalization = 260;
 
   // XLA:CPU-Next tiling parameters for matmul.
   bool xla_cpu_enable_custom_matmul_tiling = 195;
@@ -644,9 +648,7 @@ message DebugOptions {
   // Maximum number of buffers to print when debugging buffer assignment.
   int64 xla_debug_buffer_assignment_show_max = 251;
 
-  int32 xla_gpu_llvm_verification_level = 256;
-
-  // Next id: 258
+  // Next id: 256
 
   // Extra options to pass to the compilation backend (e.g. LLVM); specific
   // interpretation of these values is left to the backend.
diff --git a/xla/service/cpu/cpu_compiler.cc b/xla/service/cpu/cpu_compiler.cc
index e519cf051f..e27b3697f0 100644
--- a/xla/service/cpu/cpu_compiler.cc
+++ b/xla/service/cpu/cpu_compiler.cc
@@ -261,6 +261,20 @@ xla::cpu::HloXlaRuntimePipelineOptions GetHloXlaRuntimePipelineOptions(
   xla::cpu::HloXlaRuntimePipelineOptions options;
   options.enable_tiling_and_fusion =
       xla::GetDebugOptionsFromFlags().xla_cpu_enable_mlir_tiling_and_fusion();
+  options.enable_concat_optimization =
+      xla::GetDebugOptionsFromFlags().xla_cpu_enable_concat_optimization();
+  options.use_matmul_library =
+      xla::GetDebugOptionsFromFlags().xla_cpu_use_matmul_library();
+  options.enable_output_tensor_reuse =
+      xla::GetDebugOptionsFromFlags().xla_cpu_enable_output_tensor_reuse();
+  options.enable_concat_removal =
+      xla::GetDebugOptionsFromFlags().xla_cpu_enable_concat_removal();
+  options.enable_concat_canonicalization =
+      xla::GetDebugOptionsFromFlags().xla_cpu_enable_concat_canonicalization();
+
+  if (options.enable_concat_optimization) {
+    options.sparse_bufferization = false;
+  }
   if (xla::GetDebugOptionsFromFlags().xla_cpu_enable_custom_matmul_tiling()) {
     options.matmul_tile_sizes = {
         xla::GetDebugOptionsFromFlags().xla_cpu_matmul_tiling_m_dim(),
@@ -270,6 +284,12 @@ xla::cpu::HloXlaRuntimePipelineOptions GetHloXlaRuntimePipelineOptions(
   options.experimental_deallocation =
       xla::GetDebugOptionsFromFlags()
           .xla_cpu_enable_experimental_deallocation();
+  if (options.use_matmul_library) {
+    // Experimental deallocation segfaults if we
+    // enable xla_cpu_use_matmul_library.
+    options.experimental_deallocation = false;
+  }
+
   options.enable_avx2 = [&] {
     // Derive whether this is an x86 CPU with AVX2 enabled.
     if (!target_triple.isX86()) return false;
@@ -876,7 +896,10 @@ Status CpuCompiler::RunHloPassesAfterLayoutAssn(
   pipeline.AddPass<ReshapeDecomposer>();
 
   // Add a fusion pass now that layout assignment is done.
-  pipeline.AddPass<CpuInstructionFusion>();
+  if (getenv("XLA_ORCJIT_DISABLE_FUSION") == NULL)
+    pipeline.AddPass<CpuInstructionFusion>();
+  else
+    std::cout << "WARNING: Disabling CpuInstructionFusion\n";
 
   // The LayoutAssignment pass may leave behind kCopy instructions which are
   // duplicate or NOPs, so remove them with algebraic simplification and CSE.
diff --git a/xla/service/cpu/hlo_xla_runtime_pipeline.h b/xla/service/cpu/hlo_xla_runtime_pipeline.h
index b77436c165..e6f6db615b 100644
--- a/xla/service/cpu/hlo_xla_runtime_pipeline.h
+++ b/xla/service/cpu/hlo_xla_runtime_pipeline.h
@@ -32,6 +32,11 @@ namespace cpu {
 struct HloXlaRuntimePipelineOptions {
   bool enable_tiling_and_fusion = false;
   bool enable_fusion_outlining = true;
+  bool enable_concat_optimization = true;
+  bool use_matmul_library = false;
+  bool enable_output_tensor_reuse = false;
+  bool enable_concat_removal = false;
+  bool enable_concat_canonicalization = false;
   bool remove_copies_to_outparams = true;
   bool sparse_bufferization = true;
   bool experimental_deallocation = false;
