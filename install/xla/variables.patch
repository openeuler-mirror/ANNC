diff --git a/xla/mlir/runtime/transforms/jit_compiler.cc b/xla/mlir/runtime/transforms/jit_compiler.cc
index d3eab8374c..41abd44c00 100644
--- a/xla/mlir/runtime/transforms/jit_compiler.cc
+++ b/xla/mlir/runtime/transforms/jit_compiler.cc
@@ -22,6 +22,7 @@ limitations under the License.
 #include <string_view>
 #include <utility>
 #include <vector>
+#include <iostream>
 
 #include "absl/status/status.h"
 #include "llvm/ADT/STLExtras.h"
@@ -48,6 +49,9 @@ limitations under the License.
 #include "xla/mlir/runtime/ir/rt_ops.h"
 #include "xla/mlir/runtime/transforms/compiler.h"
 #include "xla/mlir/runtime/transforms/passes.h"
+#include "mlir/Dialect/LLVMIR/LLVMDialect.h"
+#include "mlir/Target/LLVMIR/Dialect/Builtin/BuiltinToLLVMIRTranslation.h"
+#include "mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h"
 
 namespace xla {
 namespace runtime {
@@ -62,6 +66,9 @@ static bool DebugJitCompiler() {
 #if defined(DEBUG_XLA_RUNTIME_COMPILER)
   return true;
 #endif
+  char * dump_env_var = getenv("XLA_DUMP_MLIR");
+  if (dump_env_var != NULL)
+    return true;
   return VLOG_IS_ON(5);
 }
 
@@ -304,6 +311,9 @@ MakeOptimizingTransformerForJit(llvm::TargetMachine* targetMachine) {
   };
 }
 
+
+int cluster_id = 0;
+
 /*static*/ absl::StatusOr<Executable> JitCompiler::Compile(
     std::unique_ptr<JitCompiler> compiler, std::string_view memory_region_name,
     std::optional<size_t> specialization) {
@@ -409,8 +419,78 @@ MakeOptimizingTransformerForJit(llvm::TargetMachine* targetMachine) {
   // Translate MLIR module to the LLVM module.
   auto llvm_ctx = std::make_unique<llvm::LLVMContext>();
   auto llvm_module = translateModuleToLLVMIR(compiler->module(), *llvm_ctx);
-  if (!llvm_module)
-    return compiler->Error("failed to translate module to LLVM IR");
+
+  bool hijack = false;
+  int hijackId;
+  std::string hijackPath;
+  char * hijack_path_env_var = getenv("XLA_HIJACK_PATH");
+  char * hijack_id_env_var = getenv("XLA_HIJACK_MODEL_ID");
+  char * dump_llvm_path_env_var = getenv("XLA_MLIRJIT_DUMP_LLVM_PATH");
+
+  if (hijack_path_env_var != NULL && hijack_path_env_var == NULL ||
+      hijack_path_env_var == NULL && hijack_path_env_var != NULL) {
+    std::cout << "ERROR: If you want to hijack you must specify both XLA_HIJACK_PATH and XLA_HIJACK_MODEL_ID\n";
+  }
+  else if (hijack_path_env_var != NULL) {
+    hijack = true;
+    hijackPath = std::string(hijack_path_env_var);
+    std::string tmpId = std::string(hijack_id_env_var);
+    hijackId = std::stoi(tmpId);
+
+    if (hijackId < 0) {
+      std::cout << "ERROR: XLA_HIJACK_MODEL_ID is less than zero\n";
+      hijack = false;
+    }
+  }
+
+  // Hijack the MLIR file if requested by the user
+  if (hijack && cluster_id == hijackId) {
+    std::cout << "Hijacking from " << hijackPath << " (cluster_id=" << cluster_id << ")\n";
+
+    llvm::ErrorOr<std::unique_ptr<llvm::MemoryBuffer>> fileOrErr = llvm::MemoryBuffer::getFileOrSTDIN(hijackPath);
+
+    auto sourceMgr = llvm::SourceMgr();
+    auto bufferId = sourceMgr.AddNewSourceBuffer(std::move(*fileOrErr), llvm::SMLoc());
+
+    mlir::DialectRegistry registry;
+    registry.insert<mlir::LLVM::LLVMDialect>();
+
+    // mlir::registerAllDialects(registry);
+    mlir::registerBuiltinDialectTranslation(registry);
+    mlir::registerLLVMDialectTranslation(registry);
+
+    MLIRContext context(registry, MLIRContext::Threading::DISABLED);
+    // Parse the input MLIR file.
+
+    context.allowUnregisteredDialects(true);
+
+    OwningOpRef<mlir::ModuleOp> hackedModule = parseSourceFile<mlir::ModuleOp>(sourceMgr, &context);
+
+    if (!hackedModule) {
+      return compiler->Error("Error can't load file");
+    }
+
+    // If we are JITing the model we care about (denoted by cluster_id) then
+    // hijack it
+    llvm_module = translateModuleToLLVMIR(*hackedModule, *llvm_ctx);
+
+    if (!llvm_module){
+      return compiler->Error("failed to translate module to LLVM IR");
+    }
+  }
+
+  if (dump_llvm_path_env_var != NULL) {
+    std::string llvmDumpPath = std::string(dump_llvm_path_env_var);
+    std::cout << "Dumping LLVM IR to " << llvmDumpPath << "\n";
+
+    std::error_code ec;
+    std::string output_file_name = llvmDumpPath + "llvm_output" + std::to_string(cluster_id) + ".ll";
+    llvm::raw_ostream * output_file = new llvm::raw_fd_ostream(output_file_name, ec);
+    llvm_module->print(*output_file, nullptr,
+          /*ShouldPreserveUseListOrder=*/false, /*IsForDebug=*/true);
+  }
+
+  cluster_id++;
 
   // Compile input module to the native function.
   auto engine = ExecutionEngine::CreateFromModule(
diff --git a/xla/mlir/runtime/xla-runtime-opt.cc b/xla/mlir/runtime/xla-runtime-opt.cc
index 22adfe8131..a6171fce3e 100644
--- a/xla/mlir/runtime/xla-runtime-opt.cc
+++ b/xla/mlir/runtime/xla-runtime-opt.cc
@@ -18,6 +18,9 @@ limitations under the License.
 #include "mlir/Dialect/Func/IR/FuncOps.h"  // from @llvm-project
 #include "mlir/Dialect/Math/IR/Math.h"  // from @llvm-project
 #include "mlir/Dialect/MemRef/IR/MemRef.h"  // from @llvm-project
+#include "mlir/Dialect/SCF/IR/SCF.h"  // from @llvm-project
+#include "mlir/Dialect/Tensor/IR/Tensor.h"  // from @llvm-project
+#include "mlir/Dialect/Vector/IR/VectorOps.h"  // from @llvm-project
 #include "mlir/Tools/mlir-opt/MlirOptMain.h"  // from @llvm-project
 #include "xla/mlir/math/transforms/passes.h"
 #include "xla/mlir/memref/transforms/passes.h"
@@ -28,6 +31,8 @@ int main(int argc, char **argv) {
   mlir::DialectRegistry registry;
 
   registry.insert<mlir::func::FuncDialect, mlir::memref::MemRefDialect,
+                  mlir::scf::SCFDialect, mlir::tensor::TensorDialect,
+                  mlir::vector::VectorDialect,
                   mlir::math::MathDialect, xla::runtime::RuntimeDialect,
                   mlir::async::AsyncDialect, xla::runtime::TestlibDialect>();
   mlir::func::registerAllExtensions(registry);
diff --git a/xla/runtime/execution_engine.cc b/xla/runtime/execution_engine.cc
index 1e6ab0913c..66297c9076 100644
--- a/xla/runtime/execution_engine.cc
+++ b/xla/runtime/execution_engine.cc
@@ -38,6 +38,7 @@ limitations under the License.
 #include "llvm/IR/DerivedTypes.h"
 #include "llvm/IR/IRBuilder.h"
 #include "llvm/IR/Instructions.h"
+#include "llvm/Support/DynamicLibrary.h"
 #include "llvm/Support/Error.h"
 #include "llvm/Support/MemoryBuffer.h"
 #include "llvm/Support/TargetSelect.h"
@@ -394,13 +395,48 @@ ExecutionEngine::CreateFromModule(std::unique_ptr<llvm::LLVMContext> ctx,
   llvm::orc::JITDylib &main_jd = (*jit)->getMainJITDylib();
   llvm::DataLayout data_layout = (*jit)->getDataLayout();
 
-  // Register user-provided symbols.
-  if (options.symbols_binding) {
-    auto mangle = llvm::orc::MangleAndInterner(main_jd.getExecutionSession(),
-                                               data_layout);
-    auto symbols = absoluteSymbols(options.symbols_binding(mangle));
-    if (auto err = main_jd.define(symbols))
-      return InternalError("failed to add symbols bindings: %s", ToString(err));
+  char * load_object_path_env_var = getenv("XLA_MLIRJIT_LOAD_OBJECT_PATH");
+  char * load_libs_path_env_var = getenv("XLA_MLIRJIT_LOAD_LIB_PATHS");
+
+  if (load_libs_path_env_var != NULL) {
+    std::string libs(load_libs_path_env_var);
+    const std::string delimiter = ",";
+    std::string errMsg;
+    bool ret;
+
+    // The variable supports a comma-delimited list of libraries to load, so
+    // parse the list of libraries here.
+    size_t pos = 0;
+    while ((pos = libs.find(delimiter)) != std::string::npos) {
+      std::string token = libs.substr(0, pos);
+
+      std::cout << "Loading shared library file from " << token << "\n";
+      ret = llvm::sys::DynamicLibrary::LoadLibraryPermanently(token.c_str(), &errMsg);
+      if (ret) std::cout << "LoadLibraryPermanently: " << errMsg << "\n";
+
+      libs.erase(0, pos + delimiter.length());
+    }
+
+    std::cout << "Loading shared library file from " << libs << "\n";
+    ret = llvm::sys::DynamicLibrary::LoadLibraryPermanently(libs.c_str(), &errMsg);
+    if (ret) std::cout << "LoadLibraryPermanently: " << errMsg << "\n";
+  }
+
+  if (load_object_path_env_var != NULL) {
+    std::string objectFileName(load_object_path_env_var);
+    std::cout << "Loading object file from " << objectFileName << "\n";
+
+    llvm::ErrorOr<std::unique_ptr<MemoryBuffer>> buffer = MemoryBuffer::getFile(objectFileName.c_str());
+
+    if (buffer) {
+      std::unique_ptr<llvm::MemoryBuffer> custom_obj_file = std::move(buffer.get());
+
+      if (auto err = (*jit)->addObjectFile(std::move(custom_obj_file)))
+        return InternalError("failed to add object file: %s", ToString(err));
+    }
+    else {
+      std::cout << "Failed to load the object file!\n";
+    }
   }
 
   // Resolve all exported functions to function pointers.
diff --git a/xla/service/cpu/compiler_functor.cc b/xla/service/cpu/compiler_functor.cc
index 5a877ae5ec..8ee94a4a48 100644
--- a/xla/service/cpu/compiler_functor.cc
+++ b/xla/service/cpu/compiler_functor.cc
@@ -126,8 +126,10 @@ llvm::Expected<std::unique_ptr<llvm::MemoryBuffer>> CompilerFunctor::operator()(
     }
   }
 
+  char * disable_opt_vec_env_var = getenv("XLA_ORCJIT_DISABLE_OPT_VECTORIZATION");
+
   llvm::PipelineTuningOptions pto;
-  pto.LoopVectorization = !optimize_for_size_;
+  pto.LoopVectorization = !optimize_for_size_ && disable_opt_vec_env_var != NULL;
   pto.SLPVectorization = !optimize_for_size_ && !disable_slp_vectorizer_;
   pto.LoopUnrolling = false;
 
diff --git a/xla/service/cpu/cpu_compiler.cc b/xla/service/cpu/cpu_compiler.cc
index e519cf051f..d985ca2867 100644
--- a/xla/service/cpu/cpu_compiler.cc
+++ b/xla/service/cpu/cpu_compiler.cc
@@ -876,7 +876,10 @@ Status CpuCompiler::RunHloPassesAfterLayoutAssn(
   pipeline.AddPass<ReshapeDecomposer>();
 
   // Add a fusion pass now that layout assignment is done.
-  pipeline.AddPass<CpuInstructionFusion>();
+  if (getenv("XLA_ORCJIT_DISABLE_FUSION") == NULL)
+    pipeline.AddPass<CpuInstructionFusion>();
+  else
+    std::cout << "WARNING: Disabling CpuInstructionFusion\n";
 
   // The LayoutAssignment pass may leave behind kCopy instructions which are
   // duplicate or NOPs, so remove them with algebraic simplification and CSE.
diff --git a/xla/service/cpu/cpu_options.cc b/xla/service/cpu/cpu_options.cc
index 6f4d37ab9d..42b477e7d2 100644
--- a/xla/service/cpu/cpu_options.cc
+++ b/xla/service/cpu/cpu_options.cc
@@ -26,6 +26,7 @@ const char* const kXlaForceEnableExperimentalLlvmIrGemm =
     "xla_force_enable_experimental_llvm_ir_gemm";
 const char* const kLlvmIrGemmTileSize = "xla_llvm_ir_gemm_tile_size";
 const char* const kDisableSlpVectorizer = "xla_cpu_disable_slp_vectorizer";
+const char* const kDisableVectorizeReductions = "xla_cpu_disable_vectorize_reductions";
 
 }  // namespace
 
@@ -42,7 +43,7 @@ bool OptimizeForSizeRequested(const HloModuleConfig& config) {
 bool VectorizedReduceDisabled(const HloModuleConfig& config) {
   const auto& extra_options_map =
       config.debug_options().xla_backend_extra_options();
-  return extra_options_map.count(kXlaOptimizeForSizeCpuOption) > 0;
+  return extra_options_map.count(kDisableVectorizeReductions) > 0;
 }
 
 bool SlpVectorizerDisabled(const HloModuleConfig& config) {
diff --git a/xla/service/llvm_ir/llvm_loop.cc b/xla/service/llvm_ir/llvm_loop.cc
index 4d3eb6554a..08529d072a 100644
--- a/xla/service/llvm_ir/llvm_loop.cc
+++ b/xla/service/llvm_ir/llvm_loop.cc
@@ -154,7 +154,8 @@ std::vector<llvm::Metadata*> ForLoop::GetLoopMetadata(llvm::IRBuilder<>* b) {
         *ctx, {llvm::MDString::get(*ctx, kLlvmLoopUnrollDisableMDName)}));
   }
 
-  if (prevent_vectorization_) {
+  char * disable_loop_vec_env_var = getenv("XLA_ORCJIT_DISABLE_LOOP_VECTORIZATION");
+  if (prevent_vectorization_ || disable_loop_vec_env_var != NULL) {
     result.push_back(llvm::MDNode::get(
         *ctx, {llvm::MDString::get(*ctx, kLlvmLoopVectorizeMDName),
                llvm::ConstantAsMetadata::get(b->getFalse())}));
diff --git a/xla/service/service.cc b/xla/service/service.cc
index 8a25b21fa9..40551175bb 100644
--- a/xla/service/service.cc
+++ b/xla/service/service.cc
@@ -787,11 +787,15 @@ StatusOr<std::unique_ptr<Executable>> Service::BuildExecutable(
     // Save proto state before optimizations if we want a snapshot.
     // When run_backend_only is enabled the post-optimization HLO will be the
     // same as the pre-optimization HLO.
-    if (DumpingEnabledForHloModule(*module)) {
-      hlo_proto_before_opt = std::make_unique<HloProto>(MakeHloProto(*module));
+
+    char *dump_env_var = getenv("XLA_DISABLE_ORC_OPTIMIZATIONS");
+    if (dump_env_var == NULL || dump_env_var[0] == '0' ) {
+      if (DumpingEnabledForHloModule(*module)) {
+        hlo_proto_before_opt = std::make_unique<HloProto>(MakeHloProto(*module));
+      }
+      TF_ASSIGN_OR_RETURN(module, backend->compiler()->RunHloPasses(
+                                      std::move(module), executor, options));
     }
-    TF_ASSIGN_OR_RETURN(module, backend->compiler()->RunHloPasses(
-                                    std::move(module), executor, options));
   }
 
   TF_ASSIGN_OR_RETURN(
